<!DOCTYPE html>
<html>
  <head>
  <title>Junk Drawer : LLM Skepticism</title>
  <meta charset='utf-8'>
  <meta http-equiv="X-UA-Compatible" content="chrome=1">
  <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">

  <!-- link to main stylesheet -->
  <link rel="stylesheet" type="text/css" href="https://benknoble.github.io/assets/css/styles.css" media="screen">

  <script src="/assets/js/scale.fix.js"></script>
  <script type="text/javascript" async
    src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML" >
  </script>

  <link rel="apple-touch-icon" sizes="180x180" href="/assets/img/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicon-16x16.png">
  <link rel="manifest" href="/site.webmanifest">
  <link rel="mask-icon" href="/assets/img/safari-pinned-tab.svg" color="#5bbad5">
  <meta name="msapplication-TileColor" content="#da532c">
  <meta name="theme-color" content="#ffffff">

  <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
  <![endif]-->
  <link type="application/atom+xml" rel="alternate" href="https://benknoble.github.io/feed.xml" title="Junk Drawer" />
</head>

  <body>
    <header>
  <h1>
  <a href="https://benknoble.github.io/">
  <img src='/assets/img/logo.png' alt='Junk Drawer Logo' width=32 height=32> Junk Drawer</a></h1>
  <p>For all those little papers scattered across your desk</p>
</header>

    <section>
      <nav>
  <ul>
    
    <li class="">
      <a href="https://benknoble.github.io/about/">About</a>
    </li>
    
    <li class="">
      <a href="https://benknoble.github.io/categories/">Posts</a>
    </li>
    
    <li class="">
      <a href="https://benknoble.github.io/workshops/">Workshops</a>
    </li>
    
    <li class="">
      <a href="https://benknoble.github.io/papers/">Papers</a>
    </li>
    
    <li class="">
      <a href="https://benknoble.github.io/writings/">Writings</a>
    </li>
    
    <li class="">
      <a href="https://benknoble.github.io/reading/">Reading List</a>
    </li>
    
  </ul>
</nav>

      <h1>LLM Skepticism</h1>
      <p class="meta"><span class="authors">
  
  
    D. Ben Knoble
  
</span>
 on 18 Apr 2025 in Blog</p>
<div id="post">
  <p>A brief essay to explore the business of producing and selling LLMs.</p>

<p>Hype-driven reporting on LLMs and other self-described AI tools <a href="https://thetechbubble.substack.com/p/the-phony-comforts-of-useful-idiots">lumps together
junk articles with nuggets of
“neat”</a>.
The enthusiast will say that by pointing this out, my skepticism is a matter of
moving the goalposts. Yet I have never claimed that the LLM does not work (only
that it is not superhuman). Rather, I have repeatedly pointed—out over and
over and over again—the LLM does exactly what it is designed to do. Chiefly,
it generates plausible-seeming text based on a statistical pattern. The problem
is not that LLMs are not useful tools. The problem is that the development and
use of LLMs consistently harms along the axes which I care more about.</p>

<p>For example, an enthusiast like Casey Newton can laud himself as a “real and
dangerous promoter” without engaging in any of the very real harms that exist
today. What harms? Social injustice; racial profiling; environmental hazards;
enshittification; economic damage by way of the diverting of funds away from
productive research and towards Tech, Monopoly, hype, marketing machines, and
grifts; the diverting of value away from laborers and creators towards their
bosses; the creation of a fertile breeding ground for a campaign against truth;
the destruction of a very real and very un-tragic commons; the weaponization of
data to support racist pseudo-science like eugenics and phrenology;
participation in a cultural push to over-quantify and under-qualify; and more.</p>

<p>The punchline? Generative AI and large language models are here, are real, and
are capable of great harm. That is not because they do not work, but rather
because they function precisely as intended. If the purpose of the system is
what it does, then the purpose of large language models and generative AI are,
in addition to neat problems solving tricks, the harms listed above.</p>

<p>Both in their function as a statistical model that replicates reality rather
than improving it and in their construction requiring vast amounts of energy and
capital, an LLM and the business that supports it imperils that which I care
about: a habitable, equitable, empowering world for myself, my peers, and my
children.</p>

<p>Let’s pause for a moment and take a look at a related tool: low-code or no-code
environments. I believe that such tools may have the power to enable the
exploration of new ideas in business, education, and personal computing. My
experience as a software engineer and a hobby programmer has taught me, however,
that such tools enable solving 60% to 80% of the problem while obscuring the
remaining 20% to 40%. In many contexts that is enough of a solution, but is
fundamentally insufficient in other contexts. If such tools are helpful to my
goal of the democratization of digital control then I will continue to applaud
them as I have done in the past. When such tools seek to monopolize digital
control or enable the monopolization of digital control, then I will continue to
call that out as antithetical to the modern computing movement.</p>

<p>It is my hope that such tools create a flood of <a href="https://gwern.net/doc/technology/2004-03-30-shirky-situatedsoftware.html">“situated
software”</a>—that
is, software which is uniquely situated in its social context. Software often
has a small, tightly connected pool of users who share context. As a result,
they can overcome inherent limitations—in either digital technology as a whole
or in their programming capabilities in the specifics—by social negotiation
and physical manipulation of the world around them.</p>

<p>To be clear, low-code and no-code tools are not the only ways to create such
software. Many of my role models create such situated software on a regular
basis, such as when they improve their development environments by short scripts
that only makes sense in their specific context. I and many others have also
built situated software to assist in the pursuit of joyful activities, hobbies,
art, writing, reading, and many more. For some of these latter cases, more
sophisticated general purpose programming languages are a better vehicle.</p>

<p>What characterizes situated software is not how it was implemented but who
implemented it.</p>

<p>Some of the software is used by small communities worldwide; some of it is used
by small groups in a single small area. None would make sense to anyone without
the shared social context.</p>

<p>To return to our original theme—skepticism and criticism of generative AI and
large language models—it is true that some of these low-code and no-code
environments are predicated on or assisted by LLMs. This is not by itself
harmful; however, such models as a social artifact cannot exist separately from
the harms that were enacted upon their creation. Such a separation entails
willful blindness, intentionally drawing a veil upon ourselves, to separate
artifact from creator. It is not my intent to suggest that we can never benefit
from the fruit of the poison tree<sup id="fnref:1"><a href="#fn:1" class="footnote" rel="footnote" role="doc-noteref">1</a></sup>. I do suggest however there are
alternatives readily available, and that it may take more labor from those of us
so endowed with digital control to ensure that such alternatives continue to
exist, are created anew for a modern world, and proliferate intellectually,
legally, socially, and politically, in order to foster a free ecosystem.</p>

<p>It’s <a href="https://www.wheresyoured.at/optimistic-cowardice/">really hard to be a generative-AI skeptic right
now</a>, by which I mean it
takes a lot of effort to back up my skeptical, critical positions compared to
what it takes to be optimistic. All that said, <a href="https://drewdevault.com/2025/03/17/2025-03-17-Stop-externalizing-your-costs-on-me.html">here’s one example of the cost
of LLM
optimism</a>—scraping
is a tool like any other, which means it can be wielded for good or evil. I
fundamentally <a href="https://pluralistic.net/2023/09/17/how-to-think-about-scraping/">support the idea of scraping as a productive means of
accomplishing many different kinds of
goals</a>. But
scraping that disrespects <code class="language-plaintext highlighter-rouge">robots.txt</code> and the fundamentals of being good web
citizens? That stuff wrecks the web, especially smaller systems and their
admins—scraping should not cause DDoS outages, driving up infrastructure and
human cost. To quote the article above:</p>

<blockquote>
  <p>If blasting CO2 into the air and ruining all of our freshwater and
traumatizing cheap laborers and making every sysadmin you know miserable and
ripping off code and books and art at scale and ruining our [elided] democracy
isn’t enough for you to leave this [stuff] alone, what is?</p>
</blockquote>

<p>I think—along similar lines as Ed Zitron and others—that the AI-hype
companies are dependent on the hype for revenue in terms of “stock go up.” As
others have pointed out, that explains the constant pressure to create a
narrative: the stock price goes up only if investors truly believe these
companies have found another hyperscaler market, so the companies benefit
materially from creating the narrative that they have. (See <a href="https://pluralistic.net/2025/03/15/altering-the-deal/">Altering the
deal</a> for some more info
on how stock benefits hyperscalers by inflating price/earnings ratio and why
it’s important that they keep that narrative alive.) Whether or not the market
exists is actually a separate question for these companies. For us, believing it
might not is what makes the whole thing feel like a grift (house of cards, tower
of lies, etc.). Unfortunately, those of us that are skeptical feel like we have
lots of data (qualitative and quantitative), anecdata, and experts to back up
our position. Yet media unwilling to push back and ask tough questions coupled
with expensive, aggressive marketing campaigns drowns that out for normies<sup id="fnref:2"><a href="#fn:2" class="footnote" rel="footnote" role="doc-noteref">2</a></sup> .
To be clear: I’m not saying “LLMs don’t work.” I’m saying “they don’t have the
claimed market” and “they are destructive along many axes I examine” (most of
which are more important to me than “code faster, worse”).</p>

<p>To judge by reactions of my peers, I’m not the only one who thinks these things.
I’ll try to keep being brave enough to say them.</p>

<p>If I believe that the industry of LLMs is this harmful, and if I believe that
there are alternative tools, why would I use them? I hope I’m wrong—I hope one
day I get to reflect on how this moment encouraged us to repair injustice. In
the meantime, please stop dismissing my objections as lack of skill or fear of
change.</p>

<h2 id="notes">Notes</h2>

<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:1">
      <p>As Cory Doctorow likes to explain it, buying posters and pens from Amazon
to support your protest is better than not protesting at all. Sometimes we
have to accept the imperfection of the world we inhabit in order to wage the
fight against other imperfections. This should not be taken as a version of
“the ends justify the means.” Rather, this is the pragmatic understanding
that in all things there are trade-offs. <a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:2">
      <p>Which I am emphatically not using in a pejorative sense: see <a href="https://youtu.be/O33NK52ZmUk?si=SNgbdd8CCKK29LRH&amp;t=997">this part of
a talk I gave last year
(16:37)</a> about
democratizing technology’s “elite” label. <a href="#fnref:2" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
  </ol>
</div>

</div>
<hr/>
<h4>Tags:</h4>
<ul class="tags">
  
    <li>
      <a href="https://benknoble.github.io/tags#llm" class="tag">
        llm
      </a>
    </li>
  
</ul>

<div id="post-categories">
  <h4>Categories:
  
    <a href="/categories/#blog">Blog</a>
    
  
  </h4>
</div>

<div id="disqus_thread"></div>
<div class="load-comments" onclick="load_comments(this)">Load Comments</div>
<script>
  var disqus_shortname = 'https-benknoble-github-io';
  var disqus_config = function () {
    this.page.url = "https://benknoble.github.io/blog/2025/04/18/skepticism/";
    this.page.identifier = "/blog/2025/04/18/skepticism";
  };

  function load_comments(div) {
    var d = document, s = d.createElement('script');
    s.type = 'text/javascript';
    s.async = true;
    s.src = '//' + disqus_shortname + '.disqus.com/embed.js';
    s.setAttribute('data-timestamp', +new Date());
    (d.head || d.body).appendChild(s);
    div.parentNode.removeChild(div)
  };
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>


<div id="post-navigation">
  
  <span id="previous">
    <a href="https://benknoble.github.io/blog/2025/04/08/musings/"
      title="Thoughts from recent conversations on LLMs">
      Previous</a>
  </span>
  
  
  <span id="no-next">Next</span>
  
</div>
<div id="back-to-posts">
  <a href="/categories/#llm-skepticism">
    Back to posts</a>
</div>

    </section>
    <footer>
<hr/>
  <ul>
    
    <li>
      <a href="https://benknoble.github.io/">Home</a>
    </li>
    
    <li>
      <a href="https://benknoble.github.io/contact/">Contact</a>
    </li>
    
    <li>
      <a href="https://benknoble.github.io/sitemap.xml">Sitemap</a>
    </li>
    
    <li>
      <a href="https://benknoble.github.io/feed.xml">RSS Feed</a>
    </li>
    
    <li>
      <a href="https://benknoble.github.io/colophon/">Colophon</a>
    </li>
    
    <li>
      <a href="https://github.com/benknoble/benknoble.github.io/blob/master/LICENSE">Copyright D. Ben Knoble</a>
    </li>
    
    <li>
      <p xmlns:cc="http://creativecommons.org/ns#" ><a href="https://creativecommons.org/licenses/by-nc-sa/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;">CC BY-NC-SA 4.0<img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1" alt=""><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1" alt=""><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/nc.svg?ref=chooser-v1" alt=""><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/sa.svg?ref=chooser-v1" alt=""></a></p>
    </li>
  </ul>
</footer>

    <!--[if !IE]><script>fixScale(document);</script><![endif]-->
    <script>
      (function() {
        var script = document.createElement('script');
        window.counter = 'https://benknoble_github_io.goatcounter.com/count'
        script.async = 1;
        script.src = '//gc.zgo.at/count.js';

        var ins = document.getElementsByTagName('script')[0];
        ins.parentNode.insertBefore(script, ins)
      })();
    </script>
  </body>
</html>
