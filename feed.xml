<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="https://benknoble.github.io/feed.xml" rel="self" type="application/atom+xml" /><link href="https://benknoble.github.io/" rel="alternate" type="text/html" /><updated>2024-12-12T20:38:21+00:00</updated><id>https://benknoble.github.io/feed.xml</id><title type="html">Junk Drawer</title><subtitle>For all those little papers scattered across your desk</subtitle><author><name>benknoble</name></author><entry><title type="html">Scraping XML sitemaps with Racket</title><link href="https://benknoble.github.io/blog/2024/12/02/advent-of-racket/" rel="alternate" type="text/html" title="Scraping XML sitemaps with Racket" /><published>2024-12-02T00:00:00+00:00</published><updated>2024-12-02T00:00:00+00:00</updated><id>https://benknoble.github.io/blog/2024/12/02/advent-of-racket</id><content type="html" xml:base="https://benknoble.github.io/blog/2024/12/02/advent-of-racket/"><![CDATA[<p>Day 2 of “Advent of Racket”</p>

<h2 id="the-project">The project</h2>

<p>Many of the smartest people I know keep an external cortex or exobrain: notes, a
<a href="https://github.com/benknoble/wiki-md">personal wiki</a>, or even a blog. Inspired
by <a href="https://pluralistic.net/2021/05/09/the-memex-method/">Cory Doctorow’s “memex
method”</a> and a
<a href="https://con.racket-lang.org">RacketCon</a> question, I’m writing again when the
mood strikes—see the uptick in posts since the middle of this year.</p>

<p>The advantage of a memex or external digital cortex is several-fold. The act of
setting my thoughts out for an audience helps me to elucidate what otherwise
might be a 10-word bullet, filed away and forgotten about. For Cory Doctorow, it
keeps information connected in a tangled web that eventually crystallizes or
nucleates into a bigger form. (<a href="/writings/blankboards/">Sound familiar? I’ve written about how my brain
often works that way, too.</a>)</p>

<h3 id="learning-from-the-past-to-look-towards-the-future">Learning from the past to look towards the future</h3>

<p>If you made it this far, you’re probably wandering what this has to do with
scraping sitemaps… as Cory Doctorow writes, “systematically reviewing your older
work” is “hugely beneficial.” Looking at the patterns (wrong and right) is a
“useful process of introspection” to improve our abilities to “spot and avoid”
pitfalls.</p>

<p>Doctorow revisits “this day in history” on the major anniversaries:</p>

<blockquote>
  <p>For more than a decade, I’ve revisited “this day in history” from my own
blogging archive, looking back one year, five years, ten years (and then,
eventually, 15 years and 20 years). Every day, I roll back my blog archives to
this day in years gone past, pull out the most interesting headlines and
publish a quick blog post linking back to them.</p>

  <p>This structured, daily work of looking back on where I’ve been is more
valuable to helping me think about where I’m going than I can say.</p>
</blockquote>

<p>This review idea fascinated me. While I don’t have the online tenure that
Doctorow does, I do have some old writing. So the idea to add a program to my
daily life to show me that writing was born.</p>

<p>The program should take a month and day (defaulting to the current) and show me
<em>every</em> post that I’ve written on that day. URLs are sufficient; I can click
them or pipe them to <code class="language-plaintext highlighter-rouge">xargs -L1 open</code>. I don’t need to worry about the year, at
least not yet. It would be an easy modification to add later though. Since I
publish an XML sitemap on my blog, we’ll scrape that rather than the raw HTML.</p>

<h2 id="the-code">The code</h2>

<p>The most up-to-date version of the script will always be in my <a href="https://github.com/benknoble/Dotfiles">Dotfiles</a>; <a href="https://github.com/benknoble/Dotfiles/blob/4f5f9cde16829914fff1ad43965f2e3e46e52c50/links/bin/blog-posts-on">here’s a permalink to the version at
time of
writing</a>.</p>

<p>We start with a stanza to make this executable by the shell but written in
Racket (and we make sure to let Vim know what to do with it, since my
<a href="https://github.com/benknoble/vim-racket/blob/master/ftdetect/racket.vim">filetype-detection
code</a>
for Racket <a href="https://github.com/benknoble/vim-racket/issues/5">doesn’t work with <code class="language-plaintext highlighter-rouge">#!</code> lines
yet</a>):</p>

<div class="language-racket highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#! /usr/bin/env racket</span>
<span class="o">#</span><span class="nv">lang</span> <span class="nv">racket</span>
<span class="c1">; vim: ft=racket</span>
</code></pre></div></div>

<p>Now we require a few libraries from the main distribution; that means this
program should work with most non-minimal Racket installations without depending
on other packages being installed:</p>

<div class="language-racket highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">(</span><span class="k">require</span> <span class="nv">xml</span>
         <span class="nv">xml/path</span>
         <span class="nv">net/http-client</span>
         <span class="nv">racket/date</span><span class="p">)</span>
</code></pre></div></div>

<p>We need to know the month and day to use for our scraping; as mentioned, we’ll
default to the current day but optionally parse values out of the command line:</p>

<div class="language-racket highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">(</span><span class="k">define</span> <span class="nv">now</span> <span class="p">(</span><span class="nf">current-date</span><span class="p">))</span>

<span class="p">(</span><span class="k">define-values</span> <span class="p">(</span><span class="nf">month</span> <span class="nv">day</span><span class="p">)</span>
  <span class="p">(</span><span class="nf">command-line</span>
   <span class="nt">#:args</span> <span class="p">([</span><span class="nf">month</span> <span class="p">(</span><span class="nf">~a</span> <span class="p">(</span><span class="nb">date-month</span> <span class="nv">now</span><span class="p">))]</span> <span class="p">[</span><span class="nf">day</span> <span class="p">(</span><span class="nf">~a</span> <span class="p">(</span><span class="nb">date-day</span> <span class="nv">now</span><span class="p">))])</span>
   <span class="p">(</span><span class="k">unless</span> <span class="p">(</span><span class="nb">string-&gt;number</span> <span class="nv">month</span><span class="p">)</span>
     <span class="p">(</span><span class="nb">error</span> <span class="s">"month should be numeric: "</span> <span class="nv">month</span><span class="p">))</span>
   <span class="p">(</span><span class="k">unless</span> <span class="p">(</span><span class="nb">string-&gt;number</span> <span class="nv">day</span><span class="p">)</span>
     <span class="p">(</span><span class="nb">error</span> <span class="s">"day should be numeric: "</span> <span class="nv">day</span><span class="p">))</span>
   <span class="p">(</span><span class="nb">values</span> <span class="p">(</span><span class="nf">~r</span> <span class="p">(</span><span class="nb">string-&gt;number</span> <span class="nv">month</span><span class="p">)</span> <span class="nt">#:min-width</span> <span class="mi">2</span> <span class="nt">#:pad-string</span> <span class="s">"0"</span><span class="p">)</span>
           <span class="p">(</span><span class="nf">~r</span> <span class="p">(</span><span class="nb">string-&gt;number</span> <span class="nv">day</span><span class="p">)</span> <span class="nt">#:min-width</span> <span class="mi">2</span> <span class="nt">#:pad-string</span> <span class="s">"0"</span><span class="p">))))</span>
</code></pre></div></div>

<p>The duplication is a bit bothersome, but in a ~40-line program I’m not
concerned for the moment. It <em>is</em> important that we pad the dates to match my
site’s URL format, which uses 2-digit months and days everywhere.</p>

<p>Next, we fire off a request to the sitemap. Notice the lack of error handling:
this doesn’t need to be production grade, so we’ll assume the request succeeds.</p>

<div class="language-racket highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">(</span><span class="k">define-values</span> <span class="p">(</span><span class="nf">_status</span> <span class="nv">_headers</span> <span class="nv">response</span><span class="p">)</span>
  <span class="p">(</span><span class="nf">http-sendrecv</span> <span class="s">"benknoble.github.io"</span> <span class="s">"/sitemap.xml"</span> <span class="nt">#:ssl?</span> <span class="no">#t</span><span class="p">))</span>
</code></pre></div></div>

<p>Now <code class="language-plaintext highlighter-rouge">response</code> is an <a href="https://docs.racket-lang.org/reference/ports.html#%28tech._input._port%29"><em>input
port</em></a>:
we can read from it, but we haven’t materialized a full (byte)string yet. We
know it contains an XML document, so let’s read it as XML, extract the main
document, and turn that into an
<a href="https://docs.racket-lang.org/xml/index.html#%28def._%28%28lib._xml%2Fprivate%2Fxexpr-core..rkt%29._xexpr~3f%29%29">xexpr</a>:</p>

<div class="language-racket highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">(</span><span class="k">define</span> <span class="nv">doc</span>
  <span class="p">(</span><span class="nf">xml-&gt;xexpr</span> <span class="p">(</span><span class="nf">document-element</span> <span class="p">(</span><span class="nf">read-xml</span> <span class="nv">response</span><span class="p">))))</span>
</code></pre></div></div>

<p>Almost done: we can query the document for the URLs (which happen to be <code class="language-plaintext highlighter-rouge">loc</code>
elements) and filter them by our month-day combo:</p>

<div class="language-racket highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">(</span><span class="k">define</span> <span class="nv">locations</span>
  <span class="p">(</span><span class="nf">se-path*/list</span> <span class="o">'</span><span class="p">(</span><span class="nf">loc</span><span class="p">)</span> <span class="nv">doc</span><span class="p">))</span>

<span class="p">(</span><span class="k">define</span> <span class="nv">posts</span>
  <span class="p">(</span><span class="nf">filter-map</span>
   <span class="p">(</span><span class="k">λ</span> <span class="p">(</span><span class="nf">loc</span><span class="p">)</span>
     <span class="p">(</span><span class="nb">regexp-match</span> <span class="p">(</span><span class="nb">pregexp</span> <span class="p">(</span><span class="nf">~a</span> <span class="s">".*"</span> <span class="nv">month</span> <span class="s">"/"</span> <span class="nv">day</span> <span class="s">".*"</span><span class="p">))</span> <span class="nv">loc</span><span class="p">))</span>
   <span class="nv">locations</span><span class="p">))</span>
</code></pre></div></div>

<p>Note how useful <code class="language-plaintext highlighter-rouge">filter-map</code> is with <code class="language-plaintext highlighter-rouge">regexp-match</code>: <code class="language-plaintext highlighter-rouge">filter-map</code> discards any
<code class="language-plaintext highlighter-rouge">#f</code> results from the mapping function, while <code class="language-plaintext highlighter-rouge">regexp-match</code> returns <code class="language-plaintext highlighter-rouge">#f</code> for
any inputs that don’t match. Simultaneously it transforms matching inputs to
describe the matches.</p>

<p>Finally, we display all the (newline-separated) results! We use <code class="language-plaintext highlighter-rouge">first</code> to
extract the full original input string because the earlier <code class="language-plaintext highlighter-rouge">regexp-match</code>
produces <code class="language-plaintext highlighter-rouge">(list full-match sub-group ...)</code>; our <code class="language-plaintext highlighter-rouge">full-match</code> is the whole string
because we bracket <code class="language-plaintext highlighter-rouge">month/day</code> with <code class="language-plaintext highlighter-rouge">.*</code> patterns.</p>

<div class="language-racket highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">(</span><span class="nb">for-each</span> <span class="p">(</span><span class="nf">compose1</span> <span class="nv">displayln</span> <span class="nv">first</span><span class="p">)</span> <span class="nv">posts</span><span class="p">)</span>
</code></pre></div></div>

<p>And that’s a wrap!</p>

<h3 id="use">Use</h3>

<p>In practice, I try to run <code class="language-plaintext highlighter-rouge">blog-posts-on</code> (the name of the script) once a day.
Sometimes I forget, so I build up a range of month/day combinations with
something like (Zsh):</p>

<div class="language-zsh highlighter-rouge"><div class="highlight"><pre class="highlight"><code>print <span class="nt">-l</span> <span class="nt">--</span> 11<span class="se">\ </span><span class="o">{</span>17..22<span class="o">}</span> | xargs <span class="nt">-L1</span> blog-posts-on
</code></pre></div></div>

<p>That gets me the posts for November 17th through 22nd, for example. If I want to
open them all immediately, I pipe that to <code class="language-plaintext highlighter-rouge">xargs -L1 open</code> as mentioned
(substitute <code class="language-plaintext highlighter-rouge">xdg-open</code> or equivalent on your operating system).</p>

<h3 id="full-code">Full code</h3>

<div class="language-racket highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#! /usr/bin/env racket</span>
<span class="o">#</span><span class="nv">lang</span> <span class="nv">racket</span>
<span class="c1">; vim: ft=racket</span>

<span class="p">(</span><span class="k">require</span> <span class="nv">xml</span>
         <span class="nv">xml/path</span>
         <span class="nv">net/http-client</span>
         <span class="nv">racket/date</span><span class="p">)</span>

<span class="p">(</span><span class="k">define</span> <span class="nv">now</span> <span class="p">(</span><span class="nf">current-date</span><span class="p">))</span>

<span class="p">(</span><span class="k">define-values</span> <span class="p">(</span><span class="nf">month</span> <span class="nv">day</span><span class="p">)</span>
  <span class="p">(</span><span class="nf">command-line</span>
   <span class="nt">#:args</span> <span class="p">([</span><span class="nf">month</span> <span class="p">(</span><span class="nf">~a</span> <span class="p">(</span><span class="nb">date-month</span> <span class="nv">now</span><span class="p">))]</span> <span class="p">[</span><span class="nf">day</span> <span class="p">(</span><span class="nf">~a</span> <span class="p">(</span><span class="nb">date-day</span> <span class="nv">now</span><span class="p">))])</span>
   <span class="p">(</span><span class="k">unless</span> <span class="p">(</span><span class="nb">string-&gt;number</span> <span class="nv">month</span><span class="p">)</span>
     <span class="p">(</span><span class="nb">error</span> <span class="s">"month should be numeric: "</span> <span class="nv">month</span><span class="p">))</span>
   <span class="p">(</span><span class="k">unless</span> <span class="p">(</span><span class="nb">string-&gt;number</span> <span class="nv">day</span><span class="p">)</span>
     <span class="p">(</span><span class="nb">error</span> <span class="s">"day should be numeric: "</span> <span class="nv">day</span><span class="p">))</span>
   <span class="p">(</span><span class="nb">values</span> <span class="p">(</span><span class="nf">~r</span> <span class="p">(</span><span class="nb">string-&gt;number</span> <span class="nv">month</span><span class="p">)</span> <span class="nt">#:min-width</span> <span class="mi">2</span> <span class="nt">#:pad-string</span> <span class="s">"0"</span><span class="p">)</span>
           <span class="p">(</span><span class="nf">~r</span> <span class="p">(</span><span class="nb">string-&gt;number</span> <span class="nv">day</span><span class="p">)</span> <span class="nt">#:min-width</span> <span class="mi">2</span> <span class="nt">#:pad-string</span> <span class="s">"0"</span><span class="p">))))</span>

<span class="p">(</span><span class="k">define-values</span> <span class="p">(</span><span class="nf">_status</span> <span class="nv">_headers</span> <span class="nv">response</span><span class="p">)</span>
  <span class="p">(</span><span class="nf">http-sendrecv</span> <span class="s">"benknoble.github.io"</span> <span class="s">"/sitemap.xml"</span> <span class="nt">#:ssl?</span> <span class="no">#t</span><span class="p">))</span>

<span class="p">(</span><span class="k">define</span> <span class="nv">doc</span>
  <span class="p">(</span><span class="nf">xml-&gt;xexpr</span> <span class="p">(</span><span class="nf">document-element</span> <span class="p">(</span><span class="nf">read-xml</span> <span class="nv">response</span><span class="p">))))</span>

<span class="p">(</span><span class="k">define</span> <span class="nv">locations</span>
  <span class="p">(</span><span class="nf">se-path*/list</span> <span class="o">'</span><span class="p">(</span><span class="nf">loc</span><span class="p">)</span> <span class="nv">doc</span><span class="p">))</span>

<span class="p">(</span><span class="k">define</span> <span class="nv">posts</span>
  <span class="p">(</span><span class="nf">filter-map</span>
   <span class="p">(</span><span class="k">λ</span> <span class="p">(</span><span class="nf">loc</span><span class="p">)</span>
     <span class="p">(</span><span class="nb">regexp-match</span> <span class="p">(</span><span class="nb">pregexp</span> <span class="p">(</span><span class="nf">~a</span> <span class="s">".*"</span> <span class="nv">month</span> <span class="s">"/"</span> <span class="nv">day</span> <span class="s">".*"</span><span class="p">))</span> <span class="nv">loc</span><span class="p">))</span>
   <span class="nv">locations</span><span class="p">))</span>

<span class="p">(</span><span class="nb">for-each</span> <span class="p">(</span><span class="nf">compose1</span> <span class="nv">displayln</span> <span class="nv">first</span><span class="p">)</span> <span class="nv">posts</span><span class="p">)</span>
</code></pre></div></div>]]></content><author><name>D. Ben Knoble</name></author><category term="[&quot;Blog&quot;]" /><category term="racket" /><summary type="html"><![CDATA[Day 2 of “Advent of Racket”]]></summary></entry><entry><title type="html">Sapling Cage</title><link href="https://benknoble.github.io/blog/2024/11/27/sapling-cage/" rel="alternate" type="text/html" title="Sapling Cage" /><published>2024-11-27T00:00:00+00:00</published><updated>2024-11-27T00:00:00+00:00</updated><id>https://benknoble.github.io/blog/2024/11/27/sapling-cage</id><content type="html" xml:base="https://benknoble.github.io/blog/2024/11/27/sapling-cage/"><![CDATA[<p>My thoughts on Margaret Killjoy’s <em>Sapling Cage</em>.</p>

<h2 id="balance-in-all-things">Balance in all things</h2>

<p>Reading <em>Sapling Cage</em> took me back to reading fantasy as a preteen. Simply
written for a younger audience, it’s a page-turner for (nominally) grown adults,
too. Killjoy hooked me in to a world in the grips of dynamic power struggles
without complex dialogue, elaborate descriptions, or impossible backdrops. In
fact, except for the violence and a certain caldera, it all feels rather
mundane. This leaves room for the excitement of the coming of age tale, the
making of friends, the fear of discovery.</p>

<h2 id="words-actions-magic">Words, actions, magic</h2>

<p>Each of these has power. A witch must use all three.</p>

<p>Indeed, our main character Lorel observes and experiences violence for what it
is: hard, traumatic, gory, mournful. Yet she also experiences other powerful
actions: tentative allies unite against a threat; witches defend and enfold
someone who is other; a knight speaks for the weak.</p>

<p>Even on the very beginning of a journey into magic, we all learn something about
finding our power.</p>

<h2 id="as-a-cisgender-man">As a cisgender man</h2>

<p>I witnessed through Killjoy’s narrative a story of complexity: growing up as a
boy while being a girl. The main character struggles to figure out what to make
of her body—would it be easier if it matched the expectations of others? Would
such a change make her less attractive to a crush? Is this not her body,
imperfect as it is? <em>Is it ok not to like her body?</em></p>

<p>Moreover, she navigates fear and uncertainty: the fear of being found out, which
might be deadly. The uncertainty of who she can trust. Simultaneously her heart
swells with joy each time she is “girl” or “she.” Like Lorel’s friends (and even
rivals), we can all listen, learn, and love.</p>

<p>Killjoy reminds me that these questions—Lorel’s questions—are worth asking
of ourselves, and that we all experience their answers differently.</p>

<p>I highly recommend <em>Sapling Cage</em> (and my thanks to Cory Doctorow, whose
recommendation put it on my reading list).</p>]]></content><author><name>D. Ben Knoble</name></author><category term="[&quot;Blog&quot;]" /><category term="books" /><summary type="html"><![CDATA[My thoughts on Margaret Killjoy’s Sapling Cage.]]></summary></entry><entry><title type="html">Server-sent events with Racket</title><link href="https://benknoble.github.io/blog/2024/11/23/racket-sse/" rel="alternate" type="text/html" title="Server-sent events with Racket" /><published>2024-11-23T00:00:00+00:00</published><updated>2024-11-23T00:00:00+00:00</updated><id>https://benknoble.github.io/blog/2024/11/23/racket-sse</id><content type="html" xml:base="https://benknoble.github.io/blog/2024/11/23/racket-sse/"><![CDATA[<p>A small amount of server-side Racket and client-side JavaScript give me a
passable version of a reactive front-end.</p>

<h2 id="background">Background</h2>

<p>In my <a href="/workshops/14th-racket-con/">talk for 14th RacketCon</a> I
mentioned that the Frosthaven Manager can spawn a web-server for my friends and
players to interact with the app on their mobile devices. I run the entire
program on my machine, so all the state is stored in-process in one place. Edits
in the desktop GUI are propagated to my players web pages live, and their
actions translate back to the GUI in turn.</p>

<p>There’s no JavaScript framework on either the back-end or front-end. So how does
it all work?</p>

<p>There are 3 pieces to the puzzle:</p>

<ol>
  <li>The web-server does all the HTML generation: it embeds <code class="language-plaintext highlighter-rouge">fetch</code> calls in
<code class="language-plaintext highlighter-rouge">onclick</code> handlers that send POST requests back to the server, which the
server translates into actions the rest of the program knows how to handle
(but which, as mentioned in the talk, are shunted back to the GUI execution
loop rather than executed in the concurrent web-server handler threads). So
while my players mostly <em>see</em> the rendered HTML content returned by the
servers primary route, it actually supports a limited kind of
<code class="language-plaintext highlighter-rouge">URLSearchParams</code>-backed API. If you know what routes to hit, you could write
your own client to trigger game events. I’ve done so with
<a href="https://hurl.dev"><code class="language-plaintext highlighter-rouge">hurl</code></a> when playing with new features just to try it.</li>
  <li>Because I’m using <a href="https://docs.racket-lang.org/gui-easy/index.html">GUI
Easy</a>, all my game state is
<a href="https://docs.racket-lang.org/gui-easy/index.html#%28part._.Observables%29"><em>observable</em></a>.
This gives me a simple hook to subscribe to all the changes in my game’s
state, <a href="https://github.com/benknoble/frosthaven-manager/commit/7b8b4e7ed558454f373d296ca501c2fc3484776b">though it risks being too
fine-grained</a>
and I’ve been considering other options for generating notifications of
game-level events. Whatever mechanism there is, the web-server knows when
state has changed and it ought to propagate those changes to clients.</li>
  <li>The client and server agree to a <a href="https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events">server-sent
event</a>
protocol: this does require JavaScript enabled on the client (as do the click
handlers above). The protocol allows the server to retain a communication
channel to the client, which the client can use to update its view.</li>
</ol>

<p>This post focuses on the server-sent event implementation, or primarily the
latter 2 pieces.</p>

<p><strong>Note</strong>: Rather than embed the full code in those post, I’m going to link to
the implementation as it was at time of writing. Follow the links to get the
full details.</p>

<h2 id="server-sent-events">Server-sent events</h2>

<blockquote>
  <p>With server-sent events, it’s possible for a server to send new data to a web
page at any time, by pushing messages to the web page.
(<a href="https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events">MDN</a>)</p>
</blockquote>

<p>SSEs are one-way connections from server to client. Clients point a standard
JavaScript API <code class="language-plaintext highlighter-rouge">EventSource</code> at a URL that will produce a SSE-compatible
response and then attach event listeners. These listeners can operate over
<a href="https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#listening_for_message_events">generic
events</a>
or <a href="https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#listening_for_custom_events">named
events</a>.
Messages can have <a href="https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#data">arbitrary data
fields</a>
which the client must parse to decide how to use.</p>

<p>The server implements SSEs by responding with the correct MIME type and raw
<a href="https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#event_stream_format">response
format</a>.</p>

<h3 id="my-sse-protocol-for-the-frosthaven-manager">My SSE protocol for the Frosthaven Manager</h3>

<p>Before we look at implementation details, let’s get a grasp on the fundamentals
of the protocol my web-server uses atop SSEs.</p>

<ul>
  <li>All events use JSON as the interchange format for <code class="language-plaintext highlighter-rouge">data</code> fields. Racket is
capable of emitting standard JSON and JavaScript of parsing it, so this
simplifies communication.</li>
  <li>Events that manipulate the DOM <em>should</em> contain an HTML id pointing to the
node to manipulate. This simplifies the client code for finding the right node
and requires the server to consistently tag modifiable nodes with an
identifier (<code class="language-plaintext highlighter-rouge">id</code> attribute).</li>
  <li>Events that manipulate the DOM <em>should</em> contain strings that encode HTML that
can replace the <code class="language-plaintext highlighter-rouge">innerHTML</code> as needed.</li>
</ul>

<p>The last point is important: it avoids performing duplicate calculations in the
client (when a player’s HP changes, we send the new number, not an event
requesting that the HP be incremented or decremented), which makes keeping the
state in sync more reliable.</p>

<p>The simplest events in my protocol are <code class="language-plaintext highlighter-rouge">number</code> and <code class="language-plaintext highlighter-rouge">text</code>: they send an id and
a number or string that should replace the named node’s <code class="language-plaintext highlighter-rouge">innerHTML</code>. They
actually have nearly identical <a href="https://github.com/benknoble/frosthaven-manager/blob/4fb7ad6d36890478a078ce5efc97fe06cd6c1520/static/events.js#L64-L73">client
implementations</a>
and <a href="https://github.com/benknoble/frosthaven-manager/blob/4fb7ad6d36890478a078ce5efc97fe06cd6c1520/server.rkt#L890-L899">server
implementations</a>.</p>

<p>Other events are more complicated and outside the scope of this article. As an
example, the <code class="language-plaintext highlighter-rouge">player</code> event is triggered when a player object changes: ignoring
the summon data, it receives an HTML id, a mapping of sub-components to HTML
strings, and a complete HTML node. The complete node is used if the player
doesn’t already exist, allowing it to be inserted wholesale into the display.
Otherwise, we update the sub-nodes based on the mapping of HTML strings. The
<code class="language-plaintext highlighter-rouge">monster-group</code> event is similar.</p>

<h3 id="implementation-details">Implementation Details</h3>

<p>As we said earlier, the <a href="https://github.com/benknoble/frosthaven-manager/blob/4fb7ad6d36890478a078ce5efc97fe06cd6c1520/static/events.js#L1">client opens a new event
source</a>
and attaches event handlers. We <a href="https://github.com/benknoble/frosthaven-manager/blob/4fb7ad6d36890478a078ce5efc97fe06cd6c1520/server.rkt#L320">include the script on the main
page</a>.
Sending events is the server’s responsibility.</p>

<div class="language-javascript highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kd">const</span> <span class="nx">evtSource</span> <span class="o">=</span> <span class="k">new</span> <span class="nc">EventSource</span><span class="p">(</span><span class="dl">"</span><span class="s2">events</span><span class="dl">"</span><span class="p">);</span>
<span class="nx">evtSource</span><span class="p">.</span><span class="nf">addEventListener</span><span class="p">(</span><span class="dl">"</span><span class="s2">name</span><span class="dl">"</span><span class="p">,</span> <span class="nx">handler</span><span class="p">);</span>
</code></pre></div></div>

<p>The server subscribes to the GUI observables<sup id="fnref:1"><a href="#fn:1" class="footnote" rel="footnote" role="doc-noteref">1</a></sup>: when they change, the subscribers
place structured data in a <a href="https://docs.racket-lang.org/alexis-multicast/index.html">multicast
channel</a>
(<a href="https://github.com/benknoble/frosthaven-manager/blob/4fb7ad6d36890478a078ce5efc97fe06cd6c1520/server.rkt#L181-L188">example</a>).
We need a multicast channel because we create one per server (usually just one),
but each client request handler needs to be able to be able to read from it
(usually one per event source connection).</p>

<div class="language-racket highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">(</span><span class="k">define</span> <span class="nv">ch</span> <span class="p">(</span><span class="nf">make-multicast-channel</span><span class="p">))</span>
<span class="p">(</span><span class="nf">obs-observe!</span> <span class="nv">@state</span>
              <span class="p">(</span><span class="k">λ</span> <span class="p">(</span><span class="nf">state</span><span class="p">)</span>
                <span class="p">(</span><span class="nf">multicast-channel-put</span> <span class="nv">ch</span> <span class="p">(</span><span class="nf">state-event</span> <span class="nv">state</span><span class="p">))))</span>
</code></pre></div></div>

<p>Then, the server <a href="https://github.com/benknoble/frosthaven-manager/blob/4fb7ad6d36890478a078ce5efc97fe06cd6c1520/server.rkt#L254">establishes a route which implements the
SSEs</a>.
This is the same path that forms part of the URL that the client will connect
to. The route’s implementation <a href="https://github.com/benknoble/frosthaven-manager/blob/4fb7ad6d36890478a078ce5efc97fe06cd6c1520/server.rkt#L816-L825">responds with appropriate
headers</a>.
It also <a href="https://docs.racket-lang.org/web-server/http.html#%28def._%28%28lib._web-server%2Fhttp%2Fresponse-structs..rkt%29._response%2Foutput%29%29">gets an output
port</a>
it can use to write to the client.</p>

<div class="language-racket highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">(</span><span class="k">define</span> <span class="p">((</span><span class="nf">event-source</span> <span class="nv">ch</span><span class="p">)</span> <span class="nv">_req</span><span class="p">)</span>
  <span class="p">(</span><span class="k">define</span> <span class="nv">receiver</span> <span class="p">(</span><span class="nf">make-multicast-receiver</span> <span class="nv">ch</span><span class="p">))</span>
  <span class="p">(</span><span class="nf">response/output</span>
    <span class="nt">#:headers</span> <span class="p">(</span><span class="nb">list</span> <span class="p">(</span><span class="nf">header</span> <span class="o">#</span><span class="s">"Cache-Control"</span> <span class="o">#</span><span class="s">"no-store"</span><span class="p">)</span>
                    <span class="p">(</span><span class="nf">header</span> <span class="o">#</span><span class="s">"Content-Type"</span> <span class="o">#</span><span class="s">"text/event-stream"</span><span class="p">)</span>
                    <span class="c1">;; Don't use Connection in HTTP/2 or HTTP/3, but Racket's</span>
                    <span class="c1">;; web-server is HTTP/1.1 as confirmed by</span>
                    <span class="c1">;; `curl -vso /dev/null --http2 &lt;addr&gt;`.</span>
                    <span class="p">(</span><span class="nf">header</span> <span class="o">#</span><span class="s">"Connection"</span> <span class="o">#</span><span class="s">"keep-alive"</span><span class="p">)</span>
                    <span class="c1">;; Pairs with Connection; since our event source sends data</span>
                    <span class="c1">;; every 5 seconds at minimum, this 10s timeout should be</span>
                    <span class="c1">;; sufficient.</span>
                    <span class="p">(</span><span class="nf">header</span> <span class="o">#</span><span class="s">"Keep-Alive"</span> <span class="o">#</span><span class="s">"timeout=10"</span><span class="p">))</span>
    <span class="p">(</span><span class="nf">sse-output</span> <span class="nv">receiver</span><span class="p">)))</span>
</code></pre></div></div>

<p>The main loop of the response handler is to wait on the channel to produce data:
when it does, <a href="https://github.com/benknoble/frosthaven-manager/blob/4fb7ad6d36890478a078ce5efc97fe06cd6c1520/server.rkt#L833">a separate
function</a>
transforms that data into SSE format and shoves it through the port. If we don’t
get a response in time, we send a <a href="https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#event_stream_format">comment to prevent connection
timeout</a>.</p>

<div class="language-racket highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">(</span><span class="k">define</span> <span class="p">(</span><span class="nf">see-output</span> <span class="nv">receiver</span><span class="p">)</span>
  <span class="p">(</span><span class="k">λ</span> <span class="p">(</span><span class="nf">out</span><span class="p">)</span>
    <span class="p">(</span><span class="k">let</span> <span class="nv">loop</span> <span class="p">()</span>
      <span class="p">(</span><span class="k">cond</span>
        <span class="p">[(</span><span class="nb">sync/timeout</span> <span class="mi">5</span> <span class="nv">receiver</span><span class="p">)</span> <span class="nv">=&gt;</span> <span class="p">(</span><span class="nf">event-stream</span> <span class="nv">out</span><span class="p">)]</span>
        <span class="p">[</span><span class="nf">else</span> <span class="p">(</span><span class="nb">displayln</span> <span class="s">":"</span> <span class="nv">out</span><span class="p">)])</span>
      <span class="p">(</span><span class="nf">loop</span><span class="p">))))</span>
</code></pre></div></div>

<p>That’s all there is to it! I’m hoping to find a way to extract the two pieces
(client-side code and server-side implementation) into a library for other
Racket applications to use to implement server-side events more easily. Ideally
it will handle the basics of SSEs while remaining agnostic to how the
application generates and handles events. We <em>might</em> be able to be
concurrency-agnostic, though: while Racket’s <code class="language-plaintext highlighter-rouge">sync</code> is generic, most
applications probably need a single-producer multi-consumer channel. Still,
allowing any event that produces data a consumer can transform into SSE-data
might work and allow other patterns.</p>

<h2 id="notes">Notes</h2>

<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:1">
      <p>For performance reasons, some subscribers spawn a thread that sends the
message. Since GUI Easy subscribers execute serially, moving expensive work
out of the main loop quickly can help avoid bottlenecks. <a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
  </ol>
</div>]]></content><author><name>D. Ben Knoble</name></author><category term="[&quot;Blog&quot;]" /><category term="racket" /><category term="web" /><summary type="html"><![CDATA[A small amount of server-side Racket and client-side JavaScript give me a passable version of a reactive front-end.]]></summary></entry><entry><title type="html">Tip: use symmetric differences with git-range-diff</title><link href="https://benknoble.github.io/blog/2024/11/15/til-range-diff/" rel="alternate" type="text/html" title="Tip: use symmetric differences with git-range-diff" /><published>2024-11-15T00:00:00+00:00</published><updated>2024-11-15T00:00:00+00:00</updated><id>https://benknoble.github.io/blog/2024/11/15/til-range-diff</id><content type="html" xml:base="https://benknoble.github.io/blog/2024/11/15/til-range-diff/"><![CDATA[<p>I’ve <a href="/blog/2024/10/04/copy-range-diff/">been using <code class="language-plaintext highlighter-rouge">range-diff</code> for a while now</a>, but I’d been stuck with a long input
method for arguments. Today I learned a shortcut.</p>

<h2 id="primer">Primer</h2>

<p>Recall that <code class="language-plaintext highlighter-rouge">git range-diff</code> looks at the differences between two ranges:
commonly, we pass the two ranges explicitly; or, we can pass a base and two tips
to have the same effect as <code class="language-plaintext highlighter-rouge">&lt;base&gt;..&lt;tip1&gt; &lt;base&gt;..&lt;tip2&gt;</code>. The <a href="https://git-scm.com/docs/git-range-diff#Documentation/git-range-diff.txt-ltbasegtltrev1gtltrev2gt">manual
explaining this notation</a> gives the following example: “after
rebasing a branch <code class="language-plaintext highlighter-rouge">my-topic</code>, <code class="language-plaintext highlighter-rouge">git range-diff my-topic@{u} my-topic@{1}
my-topic</code> would show the differences introduced by the rebase.” So I’ve been
writing</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>g range-diff @{u} @{1} @
</code></pre></div></div>

<p>and similar variants for several months. I actually recently switched to
<a href="https://git-scm.com/docs/git-config#Documentation/git-config.txt-pushdefault"><code class="language-plaintext highlighter-rouge">push.default = current</code></a> where my <code class="language-plaintext highlighter-rouge">@{upstream}</code> is the branch I
want to pull from (often some version of <code class="language-plaintext highlighter-rouge">origin/main</code> or <code class="language-plaintext highlighter-rouge">upstream/main</code>) and
Git provides (after I push) <code class="language-plaintext highlighter-rouge">@{push}</code> as the branch I’m pushing to (<em>e.g.</em>,
<code class="language-plaintext highlighter-rouge">origin/topic</code>). With this layout, I run</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>g range-diff @{u} @{push} @
</code></pre></div></div>

<p>(There is no abbreviation for <code class="language-plaintext highlighter-rouge">@{push}</code>, sadly.)</p>

<h2 id="symmetric-diff">Symmetric diff</h2>

<p>Now, I knew that <code class="language-plaintext highlighter-rouge">git range-diff</code> also accepts a <a href="https://git-scm.com/docs/git-range-diff#Documentation/git-range-diff.txt-ltrev1gt82308203ltrev2gt">three-dot symmetric difference
notation</a>, so</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>g range-diff &lt;left&gt;...&lt;right&gt;
    -- becomes --&gt;
g range-diff &lt;right&gt;..&lt;left&gt; &lt;left&gt;..&lt;right&gt;
</code></pre></div></div>
<p>But in the past, especially prior to <code class="language-plaintext highlighter-rouge">push.default = current</code>, I had not found
this terribly useful. I was probably holding it wrong.</p>

<p>Today, I write (before pushing)</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>g range-diff @{push}... | copy-range-diff
</code></pre></div></div>

<p>and all is well. Use <code class="language-plaintext highlighter-rouge">git log [--oneline] --graph --boundary --left-right --cherry-mark
@{push}...</code> to get a feel for what ranges are being compared.</p>]]></content><author><name>D. Ben Knoble</name></author><category term="[&quot;Blog&quot;]" /><category term="git" /><summary type="html"><![CDATA[I’ve been using range-diff for a while now, but I’d been stuck with a long input method for arguments. Today I learned a shortcut.]]></summary></entry><entry><title type="html">Little utilities</title><link href="https://benknoble.github.io/blog/2024/11/15/useful-utilities/" rel="alternate" type="text/html" title="Little utilities" /><published>2024-11-15T00:00:00+00:00</published><updated>2024-11-15T00:00:00+00:00</updated><id>https://benknoble.github.io/blog/2024/11/15/useful-utilities</id><content type="html" xml:base="https://benknoble.github.io/blog/2024/11/15/useful-utilities/"><![CDATA[<p>Like many other full-time shell users, I write small utilities to add to my
toolbox. Let’s compare.</p>

<p><strong>Update 2024 November 17:</strong> Add notes on <code class="language-plaintext highlighter-rouge">git-q</code> and <code class="language-plaintext highlighter-rouge">git-vee</code>.</p>

<h2 id="parallel-thoughts">Parallel thoughts</h2>

<p>I stumbled on <a href="https://blog.plover.com/">MJD’s blog</a> via a <a href="https://git.github.io/rev_news/">Git Rev
News</a> article from last year and found <a href="https://blog.plover.com/prog/runN.html">a post
about little utilities</a>. Clearly great
minds think alike:</p>

<ul>
  <li>MJD explains an <code class="language-plaintext highlighter-rouge">f</code> command to extract a single field. It’s written in Perl. I
have a <a href="/blog/2019/09/11/fields/"><code class="language-plaintext highlighter-rouge">fields</code> script</a> that uses
dynamically-generated AWK to extract as many fields as you want. It’s a longer
name but useful in more situations.</li>
  <li>The post goes on to mention <code class="language-plaintext highlighter-rouge">runN</code>, a (mostly sequential but sometimes
parallel) command runner that replaces some simple loops. But this is a
straightforward variation on <a href="https://joeyh.name/code/moreutils/">moreutils</a>
<code class="language-plaintext highlighter-rouge">parallel</code> command<sup id="fnref:1"><a href="#fn:1" class="footnote" rel="footnote" role="doc-noteref">1</a></sup>, so that’s what I use when I remember to.</li>
</ul>

<h2 id="git">Git</h2>

<p>In <a href="https://blog.plover.com/prog/git-q.html">another post</a>, MJD mentions two Git
utilities:</p>

<ul>
  <li>Using <code class="language-plaintext highlighter-rouge">git vee</code> as a wrapper around <code class="language-plaintext highlighter-rouge">git log</code> over a symmetric difference
shows how branches have diverged. <a href="https://github.com/benknoble/Dotfiles/commit/e0ca3d3402b00edb8ea3580afa1d171d07b6e246">My take, <code class="language-plaintext highlighter-rouge">git
div</code></a>
infers the arguments that I would normally pass (like <code class="language-plaintext highlighter-rouge">base...upstream</code>) and
allows to specify them, but the inference is intentionally unsophisticated. I
consider this a companion to <code class="language-plaintext highlighter-rouge">git sbup</code> (<code class="language-plaintext highlighter-rouge">git show-branch HEAD HEAD@{upstream}
HEAD@{push}</code>).</li>
  <li>Query object information with <code class="language-plaintext highlighter-rouge">git q</code>: <a href="https://github.com/benknoble/Dotfiles/commit/79a27b666323494b0fdcc82dbb1d0b5f73b556e2">my
take</a>
is pure shell and only runs a single subprocess rather than one for each ref.
This collapses equivalent refs but is ~50x more performant (see hyperfine
output in the commit).</li>
</ul>

<p>In the words of moreutils: there’s room for more little unix utilities!</p>

<h2 id="notes">Notes</h2>

<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:1">
      <p>The <a href="https://joeyh.name/code/moreutils/">moreutils</a> syntax and manual I
vastly prefer to <a href="https://savannah.gnu.org/projects/parallel/">GNU <code class="language-plaintext highlighter-rouge">parallel</code></a>,
although GNU parallel supports niceties like a job log, retries, output
syndication, etc. For “heavy lifting,” I am forced to use GNU parallel (I
try to write detailed notes on expected uses then), but for short one-liners
I prefer the moreutils version. <a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
  </ol>
</div>]]></content><author><name>D. Ben Knoble</name></author><category term="[&quot;Blog&quot;]" /><category term="shell" /><summary type="html"><![CDATA[Like many other full-time shell users, I write small utilities to add to my toolbox. Let’s compare.]]></summary></entry><entry><title type="html">Perspective on software development models</title><link href="https://benknoble.github.io/blog/2024/11/11/git-branch-trunk-perspective/" rel="alternate" type="text/html" title="Perspective on software development models" /><published>2024-11-11T00:00:00+00:00</published><updated>2024-11-11T00:00:00+00:00</updated><id>https://benknoble.github.io/blog/2024/11/11/git-branch-trunk-perspective</id><content type="html" xml:base="https://benknoble.github.io/blog/2024/11/11/git-branch-trunk-perspective/"><![CDATA[<p><strong>Update 2024 November 22: I may have some misunderstandings about trunk-based
development, and this article needs a (as-of-yet incomplete) rewrite as a
result.</strong></p>

<p>If I believe <a href="/about/#me">simple questions have complex answers</a>, then it’s no surprise that I have a complicated take on the following
question: branch-based or trunk-based development? Which is better, and why?</p>

<p>As usual, though, <em>we’re asking the wrong questions.</em> For spoilers, jump to the
<a href="#conclusion">conclusion</a>.</p>

<h2 id="impetus-opinion-and-advantage-without-mechanism-or-goal">Impetus: opinion and advantage without mechanism or goal</h2>

<p>Part of this post is a reply to posts like <a href="https://trishagee.com/2023/05/29/why-i-prefer-trunk-based-development/">Trisha Gee’s “Why I prefer
trunk-based
development”</a>.
If you don’t care for musings on that, skip to <a href="#analysis">the beginning of my
analysis</a> for the rest of the post, which examines the tradeoffs of
branch-based and trunk-based development in light of 5 pillars.</p>

<p>Gee outshines many of her peers with her titular framing: the article explores
<em>her</em> preferences based on <em>her</em> experience. Too many answers to the question
of “to branch or not to branch” want to convince you of their absolute
correctness, shades of gray be damned. And if that kind of extreme conviction
sets off your spidey senses, it’s time to double-check: are the authors of such
answers trying to sell you something?</p>

<p>Others repeat tired claims, often without evidence. This is cargo-cult
programming and should be approached with the same skepticism: <a href="https://chelseatroy.com/2022/04/18/best-practice-is-not-a-reason-to-do-something/">“Best Practice”
is not a reason to do something</a>.</p>

<p>Gee stands out, then, for speaking personally and from professional experience.
Her introduction winds you up for a “when I was at X and we did Y, we found Z”
tale. These stories form the basis of mature programmer thinking: I learn from
your experience and can better judge appropriate tradeoffs thanks to your lived
and earned wisdom. <strong>From Gee’s analysis of tradeoffs, I hoped to learn and to
be better equipped to analyze my own.</strong> The results might be measurable or gut
feelings, and we would learn from both.</p>

<p>The main article falls flat.</p>

<p>Teed up for story time, we find instead a collection of opinion presented as
fact. This being the internet, of course we find opinion: there must be memories
that inform Gee’s opinions (or else we are reading another cargo-cult piece, and
I want to assume positive intent of Gee, whom I don’t know). We can’t extricate
our opinions from the experiences that shape us. Thus Gee speaks from experience
but shares none of it<sup id="fnref:3"><a href="#fn:3" class="footnote" rel="footnote" role="doc-noteref">1</a></sup>. For example, Gee claims</p>

<blockquote>
  <p>Integrating small changes regularly into your code is usually less painful
than a big merge at the end of a longer period of time.</p>
</blockquote>

<p>This is probably true (“usually”), but comes with none of the analysis that lets
us discern when or why. We’ll examine specific claims later; for now, we are
disappointed in yet another “this is the way” string of paragraphs.</p>

<p>What are we missing? We have a set of opinions which are presumably backed by
the author’s experience and which provide, according to her, some advantage. We
lack</p>

<ul>
  <li>the actual mechanism by which these opinions are practiced, and</li>
  <li>a set of goals or desires against which we can judge the tradeoffs of
different approaches and their effects.</li>
</ul>

<p>We don’t seek analysis to ground our precious art in hard-to-find evidence<sup id="fnref:4"><a href="#fn:4" class="footnote" rel="footnote" role="doc-noteref">2</a></sup>
or to participate in <a href="https://pluralistic.net/2024/10/29/hobbesian-slop/">empiricism
washing</a><sup id="fnref:2"><a href="#fn:2" class="footnote" rel="footnote" role="doc-noteref">3</a></sup>; rather, we aim
to derive from shared opinions lessons we apply to our own situations. We
welcome opinion. For claims of advantage, we insist on analysis in order to
integrate that opinion.</p>

<p>There is other material about the mechanisms of branch- and trunk-based
workflows. <a href="https://git-scm.com/book/en/v2/Distributed-Git-Distributed-Workflows">Pro Git even covers
some</a>, as
does <a href="https://git-scm.com/docs/gitworkflows"><code class="language-plaintext highlighter-rouge">git help workflows</code></a>. Still I want
to mix discussion of tradeoff with implementation mechanism: I find this
clarifies my thoughts.</p>

<p><a id="analysis"></a>We’ll take Gee’s 5 points for trunk-based workflows and
distill both mechanism and tradeoff for branch- and trunk-based workflows. By
the end, you’ll see how I view the wide world of Git use.</p>

<h2 id="speed-and-efficiency">Speed and Efficiency</h2>

<p>Gee claims that trunk-based development means code is integrated more quickly
and more efficiently:</p>

<blockquote>
  <p>This model allows for quicker integrations and fewer merge conflicts. […] It
might seem fast to develop your fixes and improvements on a separate branch
that isn’t impacted by other developers’ changes, but you still have to pay
that cost at some point. Integrating small changes regularly into your code is
usually less painful than a big merge at the end of a longer period of time.</p>
</blockquote>

<p>Here “integrated” code is code that has been combined together to serve some
purpose. Typically it is independently developed code, often for disparate
features or fixes.</p>

<p>Because we lack mechanism, we’re going to take trunk-based development’s
mechanism to mean something like</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>while ! git push; do
    git pull --rebase
done
</code></pre></div></div>

<p>In other words, rebase your single shared branch locally until you are able to
win the push race—after all, if I push first, Git will reject your
non-fast-forward push. (You may merge instead of rebase, but that becomes messy
for no productive reason.)</p>

<p>What is branch-based development’s equivalent workflow? It depends on your team:
the patterns I’ve seen are:</p>
<ul>
  <li>On-demand: Don’t integrate the upstream branch into the topic branch unless
there are conflicts that need resolved or upstream features that the topic
wants. Only then perform a rebase or merge, as desired. Many open-source
projects frown on merging from upstream when it is avoidable: prefer to base
your work on the code that it needs, meaning you will need to rebase if you
need new work.</li>
  <li>Continuous: Integrate the upstream branch constantly, typically via merge. I
see this when “Require branches to be up to date before merging” is enabled
for a repository, and especially when the default (or only) merge strategy is
<a href="/blog/2024/08/02/github-squash/">squashing</a>. In the corporate
environments I’ve seen this in, pushing otherwise unnecessary merges which
clutter the PR is fine since they will disappear anyway.</li>
</ul>

<p>I personally keep to a middle-ground of rebasing on-demand, but more often than
“only when there are conflicts” would suggest: in centralized workflows, I try
to keep branches with PRs based on the latest main branch. In distributed
workflows, I’m less picky about updating until I start a new version of a
branch.</p>

<p>Let’s assume both workflows follow good commit hygiene (small, focused, frequent
commits) aside from debatably-unnecessary merges. Now we can examine tradeoffs:</p>

<ol>
  <li><em>All</em> integrators have to deal with conflicts eventually.</li>
  <li>Trunk-based developers and continuous branch integrators integrate code more
often by nature of the way they operate.</li>
  <li>Assuming trunk-based developers push as soon as they have a working commit
and that they work in a team, they must have to pull frequently. If they
don’t, they push far more frequently than any of their teammates, who <em>do</em>
have to pull frequently. This can be a source of friction. In solo mode, the
push is never rejected, which makes this strategy especially appealing.</li>
  <li>On-demand integrators typically have more commits to rebase or merge when
integrating because of the frequency at which it happens, and we all agree
that more commits means more probability of conflicts.</li>
  <li>On the flip side, making PR review and merge high-priority in a branch-based
workflow means few branches live long enough to deal with complex conflicts.
This might balance out against frequent integrations if a PR is quickly
merged (“near-trunk-based”) without conflicts: on-demand saves some effort
here.</li>
</ol>

<h2 id="greater-code-stability">Greater Code Stability</h2>

<p>Gee claims that trunk-based development</p>

<blockquote>
  <p>encourages frequent commits, which leads to smaller and more manageable
changes. […] In the branching model, large and infrequent merges can introduce
bugs that are hard to identify and resolve due to the sheer size of the
changes.</p>
</blockquote>

<p>Gee argues that more commits (by proxy of “more time”) lead to a higher chance
of conflicts, which I agree with above and for which I suggested a mitigation.
Then she constructs a <a id="strawman"></a><strong>strawman</strong> version of the branching
model: to compare <em>well-run</em> trunk-based development, we should also use
<em>well-run</em> branch-based development, in which ready branches are frequently
reviewed and either merged or rejected<sup id="fnref:1"><a href="#fn:1" class="footnote" rel="footnote" role="doc-noteref">4</a></sup>.</p>

<p>In a well-run branch model, buggy merges are infrequent. Said another way, a
trunk-based developer who hasn’t pulled in a while and creates a large merge
will have the same problems.</p>

<blockquote>
  <p>By frequently pulling in the other developers’ changes, and frequently pushing
small changes of working code, we know the codebase is stable and working.</p>
</blockquote>

<p>This actually depends on stable testing, as Gee writes, and is <strong>independent of
workflow.</strong> In sum, code stability depends more on practices exterior to the
particular workflow than on branch vs. trunk, personal experience and observed
correlations notwithstanding.</p>

<h2 id="enhanced-team-collaboration">Enhanced Team Collaboration</h2>

<p>Gee writes:</p>

<blockquote>
  <p>If you’re all working on your own branches, you are not collaborating. You are
competing. To see who can get their code in fastest. To avoid being stomped on
by someone else’s code changes.</p>
</blockquote>

<p>And yet, as the <code class="language-plaintext highlighter-rouge">while</code> loop demonstrates above, trunk-based developers might
stomp on each other, too. <strong>This is independent of workflow.</strong></p>

<p>This is often a social problem rather than a technical one; that is, I need to
speak with my team about the areas we’re working on and how to organize them.
Resolving that resolves many issues.</p>

<blockquote>
  <p>If you’re all working on the same branch, you tend to have a better awareness
of the changes being made. This approach fosters greater team collaboration
and knowledge sharing. In contrast, branching can create a siloed work
environment where you’re all working independently, leading to knowledge gaps
within the team.</p>
</blockquote>

<p>Conversely, if most of a small team reviews every PR, we still share knowledge.
And for large projects with many subsystems (such as the Rust compiler),
de-siloing knowledge happens via RFC and commit hygiene, not (necessarily) by
reading every pulled commit. <strong>This problem is independent of workflow.</strong></p>

<p>A few actual tradeoffs that are workflow-relevant:</p>

<ol>
  <li>Distributed development teams, whether open source or private, may not be
able to accept trunk-based contributions from community for security or
stability reasons: giving the internet commit rights to your deployment
branch is a bad idea. The Rhombus project is driven primarily by PRs but
cannot for stability, give commit rights to everyone.</li>
  <li>Conversely, small teams with no or few other collaborators can commit
directly and reserve PR workflows for those few outside contributors. The
main Racket repository looks like this (in spite of many external
contributors), as do many other open source projects with active development
communities who don’t mind core devs committing directly.</li>
</ol>

<h2 id="improved-continuous-integration-and-delivery-cicd-practices">Improved Continuous Integration and Delivery (CI/CD) Practices</h2>

<p>Gee claims trunk-based development helps CI/CD because</p>

<blockquote>
  <p>Any failures there are seen and addressed promptly, reducing the risk of nasty
failures. It’s usually easy to track down which changes caused the problem. If
the issue can’t be fixed immediately, you can back [sic] the specific changes
that caused it.</p>
</blockquote>

<p>As may by now be clear, <strong>this is independent of workflow.</strong> Tools like <code class="language-plaintext highlighter-rouge">git
blame</code> and <code class="language-plaintext highlighter-rouge">git bisect</code> are essential to tracking changes, and CI on PRs can
catch them before they are integrated. A CI system would need to warn me loudly
that a push caused a failure for me to notice: with branch-based PRs, I am
frequently looking at the status checks on a GitHub page (for example). That
doesn’t mean a trunk-based CI system couldn’t be noisy! It’s a matter of tooling
and choice, not inherent advantage.</p>

<blockquote>
  <p>It’s at merge (or rebase) time that you start to see any integration issues.
All those tests you were running on your branch “in CI” were not testing any
kind of integration at all.</p>
</blockquote>

<p>This is certainly true and is one of the main arguments for “Require branches to
be up to date before merging.” CI typically also runs on the main branch,
however.</p>

<p>I do have experience with continuous <em>deployment</em> becoming confusing with branch
models: fundamentally it’s a tooling failure, however, because we don’t have
per-PR environments. So to test a deployed PR I might be stomping on some
other PR’s dev or QA environment.</p>

<p>Heavily regulated environments (such as my current workplace) may not be able to
treat each push as a deployment to customers: instead, in some domains we have
to be careful about when we release even if we merge frequently. For our
internal customers, release on push often works fine.</p>

<h2 id="reduced-technical-debt">Reduced Technical Debt</h2>

<p>Gee claims that “merge hell” contributes to technical debt, and I agree: it
creates temptation for quick resolution rather than careful design. All
technical debt is tradeoff, though, and we usually choose to accept some.</p>

<blockquote>
  <p>you may […] accept suggestions from your IDE that resolve the merge but that
you don’t fully understand.</p>
</blockquote>

<p>Not understanding code you produced via tool <strong>is independent of workflow.</strong>
Stop doing that. (Code review <em>may</em> catch this problem but is not a failure-free
safety net. See the “swiss cheese” model of code review.)</p>

<blockquote>
  <p>With trunk-based development, frequent merges and smaller changes make it
easier to manage and reduce the build-up of technical debt.</p>
</blockquote>

<p>Replace “trunk-based” with “branch-based”: does the sentence still ring true? I
think so. <strong>This problem is independent of workflow.</strong> Our assumptions of commit
hygiene support the claim of independence.</p>

<h2 id="conclusion">Conclusion</h2>

<p>See if this sounds right to you:</p>

<blockquote>
  <p>[Software development] requires a mindset, a culture, within the development
team. You need to frequently merge in other developers’ changes into your own
code. You need to commit small changes, frequently, which requires you to only
change small sections of the code and make incremental changes, something
which can be a difficult habit to get used to. Pair programming, comprehensive
automated testing, and maybe code reviews are key practices to helping all the
team to adopt the same approach and culture.</p>
</blockquote>

<p>Gee actually wrote these words about trunk-based development, yet I find they
apply equally to branch-based development! What happened? Presumptuously, I
suspect Gee spent time with branch-based teams that didn’t observe this culture
of commit hygiene and time with trunk-based teams that did. That kind of
anecdata can taint our view of a workflow <em>even when most of the salient
problems are workflow-independent</em>, which <a href="#strawman">leads us to create strawmen out of
poor habits</a>.</p>

<p>I leave you with the following thoughts:</p>
<ul>
  <li>After analysis, the major tradeoffs of either workflow are needed tooling,
conflict resolution, and how to do code review. Most of the rest is a problem
of software development and team culture than a problem of specific choice of
workflow. So <em>pick what works for you</em>.</li>
  <li>Perhaps the true question we should be asking is: what are the tradeoffs of
following or not following good commit hygiene? Most engineers have some
intuition for these tradeoffs, yet we all find large variety in adherence to
commit hygiene. My analysis in this article suggests that good commit hygiene
undergirds most of the advantages Gee ascribes to trunk-based development.
Maybe that’s the real change we need to convince people to make?</li>
  <li>It <em>may</em> be the case that trunk-based development acts as a stronger forcing
function for well-tested code, commit hygiene, and all the rest. Gee makes
some claims to this effect, and I cannot personally evaluate them. I have seen
struggling branch-based teams who adopt better test and commit hygiene come to
benefit—the poster children of good branch-based development would be Git,
Vim, Rust, and similar projects. Which style is more likely to force what
practices is a very different article and set of claims, though!<sup id="fnref:5"><a href="#fn:5" class="footnote" rel="footnote" role="doc-noteref">5</a></sup></li>
</ul>

<p><a id="postscript"></a>PS Gee later writes in comments:</p>

<blockquote>
  <p>It all comes down to discipline, and the team. For me, I prefer to see
IMMEDIATELY if there are any problems caused by any developer’s commit. I
prefer people not to commit if the trunk is red. I prefer people to fix
problems AS SOON as they occur, and if they cannot be fixed inside 5 minutes
(say), back out that commit and fix it locally. I prefer to work on the same
codebase as everyone else, and not some isolated branch, even if that branch
is only a day old.</p>
</blockquote>

<p>This is what I expected coming in: “my preference is X, but it all comes down to
good hygiene.” I would still have preferred to see what “back out the commit”
means, though I assume it’s some version of <code class="language-plaintext highlighter-rouge">git revert</code>. Even here, “as soon as
they occur” can still be “when PR tests catch the problem.”</p>

<p>Another commenter writes “even if you only ever work on main you absolutely do
have a local branch that is separate from the remote branch,” which is an
insightful perspective: with Git’s model, even centralized workflows don’t force
you to synchronize for every change. There is always more than one branch if you
have a remote.</p>

<p>PPS A future post will cover my own workflows in various setups and
situations—keep an eye on the RSS feed for that!</p>

<h2 id="notes">Notes</h2>

<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:3">
      <p>See <a href="#postscript">the postscript</a> for a shift: in the comments, we see
more of Gee’s thought process. <a href="#fnref:3" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:4">
      <p>Though evidence is certainly welcome to inform tradeoffs. See for example
<a href="/blog/2024/09/14/benchmarking-pict-equality-pt-2/">performance comparisons</a> or <a href="https://www.hillelwayne.com/talks/ese/">What we know we
don’t know</a>. <a href="#fnref:4" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:2">
      <p>See also <a href="https://locusmag.com/2021/05/cory-doctorow-qualia/">Cory Doctorow’s essay on Qualia</a> <a href="#fnref:2" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:1">
      <p>Rejected branches that need follow up work to become ready are treated as
new versions even when they share commits; in other words, think
email-driven “v1/2/3” workflows even when working with GitHub’s UI and
rebases. On GitHub, you might also close a PR and start a new one if the new
work is significantly different from the old, whether you rebase or not. <a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:5">
      <p>Evaluating them has to be sensitive to seniority, too: if you only have
senior engineers in your trunk pool and juniors in your branch pool, well,
that’s the correlation you measure. And I suspect that many of us that are
in poor branch-based communities now are surrounded by juniors in corporate
environments that don’t reward well the teams who spend time on these
considerations; when we move to a pod of seniors that have already adopted
the baseline assumptions (commit hygiene, etc.), whether they choose
trunk-based or branch-based development, the model surely shines. <a href="#fnref:5" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
  </ol>
</div>]]></content><author><name>D. Ben Knoble</name></author><category term="[&quot;Blog&quot;]" /><category term="git" /><summary type="html"><![CDATA[Update 2024 November 22: I may have some misunderstandings about trunk-based development, and this article needs a (as-of-yet incomplete) rewrite as a result.]]></summary></entry><entry><title type="html">Copying a git-range-diff to GitHub</title><link href="https://benknoble.github.io/blog/2024/10/04/copy-range-diff/" rel="alternate" type="text/html" title="Copying a git-range-diff to GitHub" /><published>2024-10-04T00:00:00+00:00</published><updated>2024-10-04T00:00:00+00:00</updated><id>https://benknoble.github.io/blog/2024/10/04/copy-range-diff</id><content type="html" xml:base="https://benknoble.github.io/blog/2024/10/04/copy-range-diff/"><![CDATA[<p>I’ve been using <code class="language-plaintext highlighter-rouge">git range-diff</code> for the past few months to explain changes
between versions of a patch series, such as different versions of a branch after
responding to review comments on a Pull Request. This post explains how I use
post the output for Markdown-ish consumption on GitHub.</p>

<h2 id="primer">Primer</h2>

<p>If you didn’t know, <code class="language-plaintext highlighter-rouge">git range-diff</code> is the standard way in Git to document
changes between versions of a patch series such as you might find sent to a
development mailing list. For example, <code class="language-plaintext highlighter-rouge">git format-patch</code> can include it
automatically in the email so that, when responding to review comments with a
new version, reviewers understand what’s changed.</p>

<p>This all seems only relevant to email-driven workflows, but I argue that it is
also useful for GitHub- or other web- driven workflows. For example: I work on a
branch and submit a Pull Request on GitHub. After some review comments, I may
create some <code class="language-plaintext highlighter-rouge">--fixup</code> commits and <code class="language-plaintext highlighter-rouge">rebase --autosquash</code> them in, perhaps editing
commit messages, or make any number of other changes. When the time comes to
<code class="language-plaintext highlighter-rouge">push --force-with-lease --force-if-includes</code>, the only recourse my reviewers
have to understand the changes is GitHub’s “View changes” button, which attempts
a textual diff between the files at the old and new branch tip.</p>

<p>Yet a range-diff can capture so much more! Consider, for example, this
range-diff from a Racket PR I submitted:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>1:  907d3ea366 = 1:  35c19f1e83 docs: capitalize the noun Git
2:  665e037505 ! 2:  6088cd1567 docs: mention the Vi command to add sections
    @@ pkgs/racket-doc/scribblings/style/textual.scrbl: read code on monitors that acco
     +So, when you create a file, add a line with @litchar{;; } followed by ctrl-U 99
     +and @litchar{-}. @margin-note*{In Vi, the command is 99a- followed by Esc.} When
     +you separate "sections" of code in a file, insert the same line. These lines
    -+help both writers and readers to orient themselves in a file. In scribble use
    ++help both writers and readers to orient themselves in a file. In Scribble use
     +@litchar|{@; }| as the prefix.

      @; -----------------------------------------------------------------------------
3:  808676897e = 3:  1e7b35da0a docs: link fx+ and unsafe-fx+
4:  ca7d2a2a56 = 4:  c3e32a5afa docs: correct Git pull command
5:  1108c95343 = 5:  372bbd4ad5 docs: unquote "merge commit"
6:  1374b3b095 &lt; -:  ---------- docs: italicize "e.g."
7:  8f3f1cd517 = 6:  e48525eeb7 docs: correct macro body
-:  ---------- &gt; 7:  38b3c0a75e docs: make explicit the convention for Latin
</code></pre></div></div>

<p>GitHub won’t show you this difference: I capitalized a word in an old commit
message, removed the commit that italicized Latin abbreviations and added one
that clarified said convention. I prefer to provide my reviewers with this
information to help them understand the changes I’ve made (and to help future
readers who may be curious, though I admit this is unlikely in most cases).</p>

<h2 id="sharing-a-range-diff-in-markdown-format">Sharing a range-diff in Markdown format</h2>

<p>A range-diff can get quite large if there are substantial code
changes—arguably, the patch series should become a new branch/PR at such a
point, but that is not often how things operate in practice. I used to paste
range-diffs in code blocks like you see above, but with length and GitHub’s
comment/review interface they became unwieldy.</p>

<p>Instead, I’ve started pasting them inside an HTML <code class="language-plaintext highlighter-rouge">details</code> block so that they
may be collapsed, summarized, and expanded as desired. I often did this by hand,
but <a href="https://github.com/benknoble/Dotfiles/blob/master/links/bin/copy-range-diff">here’s the script I now use called <code class="language-plaintext highlighter-rouge">copy-range-diff</code></a>:</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#! /bin/sh</span>

<span class="o">{</span>
  <span class="nb">printf</span> <span class="s1">'%s\n'</span> <span class="s1">'&lt;details&gt;&lt;summary&gt;range-diff:&lt;/summary&gt;'</span> <span class="s1">''</span> <span class="s1">'```'</span>
  <span class="nb">cat
  printf</span> <span class="s1">'%s\n'</span> <span class="s1">'```'</span> <span class="s1">''</span> <span class="s1">'&lt;/details&gt;'</span>
<span class="o">}</span> | pbcopy
</code></pre></div></div>

<p>This script reads standard in and pipes a modified version of it to a clipboard
command (Linux users probably prefer an <code class="language-plaintext highlighter-rouge">xsel</code> variant). Placed on the clipboard
after <code class="language-plaintext highlighter-rouge">git range-diff … | copy-range-diff</code> is an HTML <code class="language-plaintext highlighter-rouge">details</code> block containing
a Markdown code-fence which is easy to paste into GitHub or similar interfaces.
Sometimes I will add a short summary to the summary tag; other times, I leave
just the mention of a range-diff.</p>

<p>A small tweak should work for pure HTML output so that instead of triple-tick
Markdown fences we emit <code class="language-plaintext highlighter-rouge">&lt;pre&gt;</code> tags.</p>

<details><summary>Here's the earlier range-diff, in a details block</summary>

<!-- For some reason, Jekyll doesn't know how to process Markdown fences here,
     so trick it with HTML. -->

<pre class="highlight">
<code>1:  907d3ea366 = 1:  35c19f1e83 docs: capitalize the noun Git
2:  665e037505 ! 2:  6088cd1567 docs: mention the Vi command to add sections
    @@ pkgs/racket-doc/scribblings/style/textual.scrbl: read code on monitors that acco
     +So, when you create a file, add a line with @litchar{;; } followed by ctrl-U 99
     +and @litchar{-}. @margin-note*{In Vi, the command is 99a- followed by Esc.} When
     +you separate "sections" of code in a file, insert the same line. These lines
    -+help both writers and readers to orient themselves in a file. In scribble use
    ++help both writers and readers to orient themselves in a file. In Scribble use
     +@litchar|{@; }| as the prefix.

      @; -----------------------------------------------------------------------------
3:  808676897e = 3:  1e7b35da0a docs: link fx+ and unsafe-fx+
4:  ca7d2a2a56 = 4:  c3e32a5afa docs: correct Git pull command
5:  1108c95343 = 5:  372bbd4ad5 docs: unquote "merge commit"
6:  1374b3b095 &lt; -:  ---------- docs: italicize "e.g."
7:  8f3f1cd517 = 6:  e48525eeb7 docs: correct macro body
-:  ---------- &gt; 7:  38b3c0a75e docs: make explicit the convention for Latin</code>
</pre>

</details>]]></content><author><name>D. Ben Knoble</name></author><category term="[&quot;Blog&quot;]" /><category term="git" /><summary type="html"><![CDATA[I’ve been using git range-diff for the past few months to explain changes between versions of a patch series, such as different versions of a branch after responding to review comments on a Pull Request. This post explains how I use post the output for Markdown-ish consumption on GitHub.]]></summary></entry><entry><title type="html">Performance of Racket Pict Comparison, Part 2</title><link href="https://benknoble.github.io/blog/2024/09/14/benchmarking-pict-equality-pt-2/" rel="alternate" type="text/html" title="Performance of Racket Pict Comparison, Part 2" /><published>2024-09-14T00:00:00+00:00</published><updated>2024-09-14T00:00:00+00:00</updated><id>https://benknoble.github.io/blog/2024/09/14/benchmarking-pict-equality-pt-2</id><content type="html" xml:base="https://benknoble.github.io/blog/2024/09/14/benchmarking-pict-equality-pt-2/"><![CDATA[<p>I eliminate “eyeball statistics” from <a href="/blog/2024/02/15/benchmarking-pict-equality/">part 1</a>. This post is based on
<a href="https://chelseatroy.com/2021/02/26/data-safety-for-programmers/">Chelsea Troy’s “Data Safety”
series</a>,
especially <a href="https://chelseatroy.com/2021/03/12/quantitative-programming-knife-skills-part-2/">Quantitative Programming Knife Skills, Part
2</a>.</p>

<p>As usual, all code is <a href="https://github.com/benknoble/pict-equal-bench">available on GitHub</a>.</p>

<h2 id="problems">Problems</h2>

<p>In the previous post, I eyeballed distributions from box-and-whisker plots (in
addition to relying on reported timings from hyperfine) to determine which
method of comparing <code class="language-plaintext highlighter-rouge">pict</code>s is faster. Today, we’ll look at addressing two
limitations of that approach:</p>

<ol>
  <li>How confident are we that the true mean of relevant measurements is captured
by the mean of our sample distribution? We’ll compute confidence intervals
for an appropriate distribution.</li>
  <li>How likely is it that the distributions actually differ for a reason other
than random chance? We’ll use statistical tests to measure the probability of
difference being attributable to random chance (the “null hypothesis”).</li>
</ol>

<p>First, though, we’ve got to talk about distributions.</p>

<h2 id="distributions">Distributions</h2>

<p>We have (by computation) a mean and standard deviation for various facets of our
<a href="https://github.com/benknoble/pict-equal-bench">data</a>. We have enough data that assuming a normal distribution is not
unreasonable; let’s take a look. For the time benchmark data, the following code</p>

<div class="language-racket highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">(</span><span class="k">require</span> <span class="nv">sawzall</span>
         <span class="nv">data-frame</span>
         <span class="nv">threading</span>
         <span class="nv">math/statistics</span><span class="p">)</span>

<span class="p">(</span><span class="k">define</span> <span class="p">(</span><span class="nf">v-μ</span> <span class="nv">xs</span><span class="p">)</span>
  <span class="p">(</span><span class="nb">exact-&gt;inexact</span> <span class="p">(</span><span class="nf">mean</span> <span class="p">(</span><span class="nb">vector-&gt;list</span> <span class="nv">xs</span><span class="p">))))</span>

<span class="p">(</span><span class="k">define</span> <span class="p">(</span><span class="nf">v-σ</span> <span class="nv">xs</span><span class="p">)</span>
  <span class="p">(</span><span class="nf">stddev</span> <span class="p">(</span><span class="nb">vector-&gt;list</span> <span class="nv">xs</span><span class="p">)))</span>

<span class="p">(</span><span class="k">define</span> <span class="nv">t-short</span> <span class="p">(</span><span class="nf">df-read/csv</span> <span class="s">"time.csv"</span><span class="p">))</span>

<span class="p">(</span><span class="nf">~&gt;</span> <span class="nv">t-short</span>
    <span class="p">(</span><span class="nf">group-with</span> <span class="s">"bench"</span><span class="p">)</span>
    <span class="p">(</span><span class="nf">aggregate</span> <span class="p">[</span><span class="nf">cpu-μ</span> <span class="p">(</span><span class="nf">cpu</span><span class="p">)</span> <span class="p">(</span><span class="nf">v-μ</span> <span class="nv">cpu</span><span class="p">)]</span>
               <span class="p">[</span><span class="nf">cpu-σ</span> <span class="p">(</span><span class="nf">cpu</span><span class="p">)</span> <span class="p">(</span><span class="nf">v-σ</span> <span class="nv">cpu</span><span class="p">)]</span>
               <span class="p">[</span><span class="nf">real-μ</span> <span class="p">(</span><span class="nf">real</span><span class="p">)</span> <span class="p">(</span><span class="nf">v-μ</span> <span class="nv">real</span><span class="p">)]</span>
               <span class="p">[</span><span class="nf">real-σ</span> <span class="p">(</span><span class="nf">real</span><span class="p">)</span> <span class="p">(</span><span class="nf">v-σ</span> <span class="nv">real</span><span class="p">)]</span>
               <span class="p">[</span><span class="nf">gc-μ</span> <span class="p">(</span><span class="nf">gc</span><span class="p">)</span> <span class="p">(</span><span class="nf">v-μ</span> <span class="nv">gc</span><span class="p">)]</span>
               <span class="p">[</span><span class="nf">gc-σ</span> <span class="p">(</span><span class="nf">gc</span><span class="p">)</span> <span class="p">(</span><span class="nf">v-σ</span> <span class="nv">gc</span><span class="p">)])</span>
    <span class="p">(</span><span class="nf">show</span> <span class="nv">everything</span><span class="p">))</span>
</code></pre></div></div>

<p>produces</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>data-frame: 2 rows x 7 columns
┌──────────────────┬─────────┬──────────────────┬──────────────────┬─────────────────┬───────────────────┬────────────────────┐
│cpu-σ             │bench    │real-μ            │real-σ            │cpu-μ            │gc-σ               │gc-μ                │
├──────────────────┼─────────┼──────────────────┼──────────────────┼─────────────────┼───────────────────┼────────────────────┤
│1.477002129744432 │bytes    │4.225773195876289 │1.4978411739022484│4.175601374570447│0.15933274204104092│0.006529209621993127│
├──────────────────┼─────────┼──────────────────┼──────────────────┼─────────────────┼───────────────────┼────────────────────┤
│1.1370657205199777│record-dc│2.0853951890034366│1.148475651239016 │2.05893470790378 │0.16564821501258256│0.007216494845360825│
└──────────────────┴─────────┴──────────────────┴──────────────────┴─────────────────┴───────────────────┴────────────────────┘
</code></pre></div></div>

<p>Let’s plot these (<a href="https://github.com/benknoble/pict-equal-bench">code</a>):</p>

<p><img src="/assets/img/pict-time-bench-cpu-normal.svg" alt="CPU time normal distributions" />
<img src="/assets/img/pict-time-bench-real-normal.svg" alt="Real time normal distributions" />
<img src="/assets/img/pict-time-bench-gc-normal.svg" alt="GC time normal distributions" /></p>

<p>By now you might have realized that negative times don’t make sense… this
suggests the normal distribution is not an appropriate distribution for
comparison. <a href="https://stats.stackexchange.com/a/203958">It appears that the exponential or Weibull distributions might
model this process better</a>, but for
now we’ll continue taking timings and memory usage to be normally distributed
for simplification.</p>

<p>Here are the equivalent values and plots for memory (all in MiB):</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>data-frame: 2 rows x 3 columns
┌───────────────────┬──────────────────┬─────────┐
│memory-σ           │memory-μ          │bench    │
├───────────────────┼──────────────────┼─────────┤
│0.22898033579570978│0.6772037663410619│bytes    │
├───────────────────┼──────────────────┼─────────┤
│0.23704268897914643│0.5486571085821722│record-dc│
└───────────────────┴──────────────────┴─────────┘
</code></pre></div></div>

<p><img src="/assets/img/pict-time-bench-memory-normal.svg" alt="Memory normal distributions in MiB" /></p>

<h2 id="confidence-intervals">Confidence Intervals</h2>

<p>To compute a confidence interval, we’ll take the distributions to be
t-distributed and compute properties of the t-statistic (for \(\alpha = 0.05\),
a 95% confidence interval). This interval tells us where the true mean falls
with 95% probability.</p>

<p>Let’s use a critical value of 1.96, which corresponds to an assumption that the
distributions are normal (given our large sample size, the t-distribution is
close to normal) and a 95% confidence interval. The formula (letting \(s\) be
the sample standard deviation, \(\bar{x}\) the sample mean, and \(N\) the number
of samples) is</p>

\[\bar{x} \pm 1.96 \frac{s}{N}\]

<p>Here are the low and high offsets of the intervals for memory and time:</p>

<ul>
  <li>memory
    <ul>
      <li>bytes: [0.6771 MiB, 0.6773 MiB]</li>
      <li>record-dc: [0.5486 MiB, 0.5487 MiB]</li>
    </ul>

    <p><img src="/assets/img/pict-time-bench-memory-confidence.svg" alt="Memory confidence intervals in MiB" /></p>
  </li>
  <li>cpu
    <ul>
      <li>bytes: [4.175, 4.176]</li>
      <li>record-dc: [2.0586, 2.0593]</li>
    </ul>

    <p><img src="/assets/img/pict-time-bench-cpu-confidence.svg" alt="CPU time confidence intervals" /></p>
  </li>
  <li>real
    <ul>
      <li>bytes: [4.225, 4.226]</li>
      <li>record-dc: [2.085, 2.086]</li>
    </ul>

    <p><img src="/assets/img/pict-time-bench-real-confidence.svg" alt="Real time confidence intervals" /></p>
  </li>
  <li>gc
    <ul>
      <li>bytes: [0.00648, 0.00658]</li>
      <li>record-dc: [0.00716, 0.00727]</li>
    </ul>

    <p><img src="/assets/img/pict-time-bench-gc-confidence.svg" alt="GC time confidence intervals" /></p>
  </li>
</ul>

<p>The plots are zoomed in because the intervals are so narrow thanks to our high
number of samples. We can be very confident that our sample means are close to
the true mean.</p>

<h2 id="statistical-tests">Statistical tests</h2>

<p>We want to compare the memory distributions across both benchmarks, and each of
the real, cpu, and gc times across both benchmarks. We’ll use the
<a href="https://docs.racket-lang.org/t-test/index.html"><code class="language-plaintext highlighter-rouge">welch-t-test</code> function from the <code class="language-plaintext highlighter-rouge">t-test</code>
library</a><sup id="fnref:1"><a href="#fn:1" class="footnote" rel="footnote" role="doc-noteref">1</a></sup>, since we can’t assume
the variances are equal (though eyeball statistics suggests that gc variance is,
which is sensible since most gc times are 0).</p>

<p>The code to compute a t-test for memory distributions is short:</p>
<div class="language-racket highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">(</span><span class="k">require</span> <span class="nv">threading</span>
         <span class="nv">data-frame</span>
         <span class="nv">sawzall</span>
         <span class="nv">t-test</span><span class="p">)</span>

<span class="p">(</span><span class="k">define</span> <span class="nv">m</span>
  <span class="p">(</span><span class="nf">~&gt;</span> <span class="s">"memory.csv"</span> <span class="nv">df-read/csv</span>
      <span class="p">(</span><span class="nf">create</span> <span class="p">[</span><span class="nf">memory</span> <span class="p">(</span><span class="nf">memory</span><span class="p">)</span> <span class="p">(</span><span class="nb">/</span> <span class="nv">memory</span> <span class="p">(</span><span class="nb">expt</span> <span class="mi">2</span> <span class="mi">20</span><span class="p">))])))</span>

<span class="p">(</span><span class="nb">apply</span>
 <span class="nv">welch-t-test</span>
 <span class="p">(</span><span class="nf">~&gt;</span> <span class="nv">m</span>
     <span class="p">(</span><span class="nf">split-with</span> <span class="s">"bench"</span><span class="p">)</span>
     <span class="p">(</span><span class="nb">map</span> <span class="p">(</span><span class="k">λ</span> <span class="p">(</span><span class="nf">df</span><span class="p">)</span>
            <span class="p">(</span><span class="nf">~&gt;</span> <span class="nv">df</span>
                <span class="p">(</span><span class="nf">slice</span> <span class="p">[</span><span class="nf">"memory"</span><span class="p">])</span>
                <span class="p">(</span><span class="nf">df-select</span> <span class="s">"memory"</span><span class="p">)))</span>
          <span class="nv">_</span><span class="p">)))</span>
</code></pre></div></div>

<p>The result for a p-value of \(0.01\) is \(1.53 \times 10^{-187}\). That is, we
can be extremely confident that the distributions have different means: we
reject the null hypothesis that the distributions have the same mean as the
likelihood of this sample occurring given said hypothesis is nearly 0.</p>

<p>Of note, this test suggests the distributions are different <em>despite
having close means</em>: the difference between the means (0.12854665775888974) is
23.42% of the smaller of the two means and 18.98% of the larger.</p>

<p>The code for time distributions is parameterized on the column:</p>

<div class="language-racket highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">(</span><span class="k">require</span> <span class="nv">threading</span>
         <span class="nv">data-frame</span>
         <span class="nv">sawzall</span>
         <span class="nv">t-test</span><span class="p">)</span>

<span class="p">(</span><span class="k">define</span> <span class="nv">t</span> <span class="p">(</span><span class="nf">df-read/csv</span> <span class="s">"time.csv"</span><span class="p">))</span>

<span class="p">(</span><span class="nf">for/list</span> <span class="p">([</span><span class="nf">column</span> <span class="o">'</span><span class="p">(</span><span class="nf">"cpu"</span> <span class="s">"real"</span> <span class="s">"gc"</span><span class="p">)])</span>
  <span class="p">(</span><span class="nb">list</span> <span class="nv">column</span>
        <span class="p">(</span><span class="nb">apply</span>
         <span class="nv">welch-t-test</span>
         <span class="p">(</span><span class="nf">~&gt;</span> <span class="nv">t</span>
             <span class="p">(</span><span class="nf">slice</span> <span class="p">(</span><span class="nf">all-in</span> <span class="p">(</span><span class="nb">list</span> <span class="s">"bench"</span> <span class="nv">column</span><span class="p">)))</span>
             <span class="p">(</span><span class="nf">split-with</span> <span class="s">"bench"</span><span class="p">)</span>
             <span class="p">(</span><span class="nb">map</span> <span class="p">(</span><span class="k">λ</span> <span class="p">(</span><span class="nf">df</span><span class="p">)</span>
                    <span class="p">(</span><span class="nf">~&gt;</span> <span class="nv">df</span>
                        <span class="p">(</span><span class="nf">slice</span> <span class="nv">column</span><span class="p">)</span>
                        <span class="p">(</span><span class="nf">df-select</span> <span class="nv">column</span><span class="p">)))</span>
                  <span class="nv">_</span><span class="p">)))))</span>
</code></pre></div></div>

<p>The results (again with p-value \(0.01\)):</p>
<ul>
  <li>cpu: \(0.0\)</li>
  <li>real: \(0.0\)</li>
  <li>gc: \(0.8196\)</li>
</ul>

<p>I’m actually shocked that the procedure produced an (inexact) 0, and I checked
the data being fed in. I can’t explain the result beyond gesturing at floating
point math; there’s no statistical realm where we accept that this occurrence is
impossible. For now, I’ll content myself with supposing that the calculation
produces such a small number that even Racket can’t keep up, and reject the null
hypothesis for CPU and real times (there is a statistically meaningful
difference in the time the two procedures take).</p>

<p>For GC times, of course, there is insufficient evidence to reject the null
hypothesis <em>as expected</em>. Most GC times are 0! It’s reasonably more likely that
the underlying distributions are actually the same one.</p>

<h2 id="conclusion">Conclusion</h2>

<p>I feel justified in my choice of method based on the data from last time and
satisfied that I’m not relying entirely on eyeball statistics. The lack of
explanation for \(0.0\) is dissatisfying…</p>

<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:1">
      <p>There have been <a href="https://racket.discourse.group/t/could-the-t-student-distribution-be-included-in-the-math-module/2999">several interesting conversations about performing
t-tests within Racket
lately</a>,
which lead to me include these additional links: <a href="https://onecompiler.com/racket/42j3n4wdn">pasted
code</a>, <a href="https://github.com/soegaard/math/blob/student-t/math-lib/math/private/distributions/impl/student-t.rkt">@soegaard’s
fork</a>
<a href="https://math.stackexchange.com/questions/4367570/transform-students-t-distribution-to-beta-distribution">how to build the distribution from its
parts</a>. <a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
  </ol>
</div>]]></content><author><name>D. Ben Knoble</name></author><category term="[&quot;Blog&quot;]" /><category term="racket" /><category term="performance" /><category term="statistics" /><summary type="html"><![CDATA[I eliminate “eyeball statistics” from part 1. This post is based on Chelsea Troy’s “Data Safety” series, especially Quantitative Programming Knife Skills, Part 2.]]></summary></entry><entry><title type="html">Churn and Weight</title><link href="https://benknoble.github.io/blog/2024/08/07/churn-and-weight/" rel="alternate" type="text/html" title="Churn and Weight" /><published>2024-08-07T00:00:00+00:00</published><updated>2024-08-07T00:00:00+00:00</updated><id>https://benknoble.github.io/blog/2024/08/07/churn-and-weight</id><content type="html" xml:base="https://benknoble.github.io/blog/2024/08/07/churn-and-weight/"><![CDATA[<p>I examine a metric that might be correlated with churn, and I posit a new
concept for code bases called weight. I also call attention to 2 tools for
measuring churn and weight.</p>

<h2 id="churn">Churn</h2>

<p>Churn is an attribute of functions and modules: those which tend to change
frequently are said to undergo heavy churn. This is typically a symptom of tight
coupling.</p>

<p>Measuring churn can be done, for example, by looking at how often files change
in Git history. In 2018 I stole <a href="https://github.com/garybernhardt/dotfiles/blob/main/bin/git-churn">Gary Bernhardt’s
<code class="language-plaintext highlighter-rouge">git-churn</code></a>
and <a href="https://github.com/benknoble/Dotfiles/blob/master/links/bin/git-churn">made it my
own</a>. For
example, here’s what it says on Frosthaven Manager:</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># git churn | head</span>
 117 scribblings/reference.scrbl
 101 server.rkt
  94 gui/manager.rkt
  90 gui/monsters.rkt
  77 defns.rkt
  73 info.rkt
  66 monster-db.rkt
  49 manager/state.rkt
  44 manager.rkt
  35 elements.rkt
</code></pre></div></div>

<p>Unsurprisingly, the reference documentation and web server change the most
frequently, followed closely by 2 of the largest and most important GUI
components (the composite whole and the monsters). The reference documentation
changes whenever a module is added, moved, or renamed, and the web server is
changing rapidly in response to player feedback.</p>

<p>Let’s examine a related idea: <em>weight</em>.</p>

<h2 id="weight">Weight</h2>

<p>I’m using the word “weight” to refer to both how heavy a module or function is
in terms of essential complexity and to how load-bearing it is in terms of
making the system do what it does. In a mature project, we probably expect to
find a few core modules to be heavy, with a (possibly long) tail of light
supplements.</p>

<p>Since heavy modules often sit at the core of the system, they are likely to have
either lots of churn (frequent changes to the core system) or little (a stable
core with frequent changes to the supplements). In other words, churn on heavy
core modules can give us an idea of how stable our core is: having the wrong
core design is a serious challenge to the life of the project.</p>

<p>How do we measure weight? As a start, I’ll use <em>relative percentages of the
code.</em> This sounds like lines of code, but it has a subtle difference: 10k lines
of code is only 1% of a codebase with 1 million lines, but dwarfs any system
with a mere few hundred. It’s not size that matters, it’s relative size.</p>

<p>Using my
<a href="https://github.com/benknoble/Dotfiles/blob/master/links/bin/code-percent"><code class="language-plaintext highlighter-rouge">code-percent</code></a>
program, we can tabulate relevant percentages and their cumulative effects.
Here’s how it runs on Frosthaven Manager:</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># git ls-files | code-percent</span>
RowNumber  File                                      PercentTotal  CumulativePercentTotal
1          server.rkt                                7.47149       7.47149
2          gui/monsters.rkt                          6.37762       13.8491
3          scribblings/programming-scenario.scrbl    4.56775       18.4169
4          manager/state.rkt                         3.9048        22.3217
5          defns/monsters.rkt                        3.62636       25.948
6          gui/manager.rkt                           2.87059       28.8186
7          gui/player-info.rkt                       2.27393       31.0925
8          gui/markdown.rkt                          2.11482       33.2074
9          elements.rkt                              1.93583       35.1432
10         scribblings/how-to-play.scrbl             1.9292        37.0724
<span class="c"># [snip]</span>
162        README.md                                 0.0265182     100
</code></pre></div></div>

<p>This gives a different picture of the code. The reference has disappeared
(supplanted by large documents), being a mere 30 lines relative to the 15k
total. But a few core pieces of functionality (state, game definitions, and GUI
pieces) have drifted to the surface, collectively taking up roughly one third of
the size of the code. Indeed, we might now question if <code class="language-plaintext highlighter-rouge">gui/markdown.rkt</code>, which
implements a “good enough for me” Markdown-to-GUI-text widget, is holding its
weight. Conversely, it might be time to try refactoring the server or monsters
GUI again. The server is not core in the layering of pieces, but it is core to
the app’s experience. It might even contain its own core of domain pieces, which
explains its weight.</p>

<p>One other trick we can do: we can get a neat idea of the size of the tail by
showing only the rows that bump us over major (cumulative) thresholds. For
example:</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># git ls-files | code-percent | awk 'BEGIN { target = 25; } NR == 1 { print; next; } $4 &gt;= target { print; target += 25; }'</span>
RowNumber  File                                      PercentTotal  CumulativePercentTotal
5          defns/monsters.rkt                        3,62636       25,948
19         defns/scenario.rkt                        1,18006       50,3116
50         gui/table.rkt                             0,550252      75,4243
162        README.md                                 0,0265182     100
</code></pre></div></div>

<p>While the first 5 files account for 25% of the code, it takes almost another 15
to reach 50%, then another 30 to reach 75% followed by a whopping 110 to
conclude. This matches at least our expectation of a long tail.</p>]]></content><author><name>D. Ben Knoble</name></author><category term="[&quot;Blog&quot;]" /><category term="project-management" /><category term="git" /><category term="frosthaven-manager" /><category term="racket" /><summary type="html"><![CDATA[I examine a metric that might be correlated with churn, and I posit a new concept for code bases called weight. I also call attention to 2 tools for measuring churn and weight.]]></summary></entry><entry><title type="html">Developer Experience, Redux</title><link href="https://benknoble.github.io/blog/2024/08/03/devex-redux/" rel="alternate" type="text/html" title="Developer Experience, Redux" /><published>2024-08-03T00:00:00+00:00</published><updated>2024-08-03T00:00:00+00:00</updated><id>https://benknoble.github.io/blog/2024/08/03/devex-redux</id><content type="html" xml:base="https://benknoble.github.io/blog/2024/08/03/devex-redux/"><![CDATA[<p>I pull excerpts from recent <em>Communications of the ACM</em> articles relevant to
developer experience advocates and add my own commentary.</p>

<h2 id="resistance-is-your-friend">Resistance is your friend</h2>

<p>Our first article<sup id="fnref:1"><a href="#fn:1" class="footnote" rel="footnote" role="doc-noteref">1</a></sup> is an opinion piece on the nature of resistance to change.
Denning and Lyons argue that human communities prefer equilibrium to disruption
and present a framework for using that resistance to build a better case for
your new idea, disruption, or innovation. In particular, they note that only
changes in a communities otherwise-satisfied concerns will open the community to
a new equilibrium:</p>

<blockquote>
  <p>An innovation leader proposing a change of practice needs to understand and
address those concerns. Rather than run away from the resistance or trying to
overcome it by force, leaders move toward the resistance with curiosity and
humility to understand why people are committed to the current equilibrium.
The goal is discover latent concerns, which when brought to their awareness
will motivate people to move toward the proposed change. You will not find a
cause for the resistance by looking at external circumstances. You will find
its causes in the everyday conversations of people in the community.</p>
</blockquote>

<p>They write that their experience demonstrates that the best leaders “bend” with
resistance:</p>

<blockquote>
  <p>Flow with the resistance, seeking to understand the concerns behind it and
revising offers to take care of those concerns. Mobilize followers to build
social power behind your offers and neutralize the social power of the
resistance.</p>
</blockquote>

<p>What does this tell us about developer experience? Developer tools cannot be
imposed by fiat or mandate: you risk a resistance movement that outlives any
particular persons ability to declare “the way.” Worse, you don’t have the
support of the community. There may be a period of perceived success, but it
usually eventually crumbles.</p>

<p>Instead, developer tools are best created by motivating the community, listening
to their problems, and solving them together. This allows you to mobilize
excited early adopters to pave the way for majority adopters.</p>

<h2 id="devex-in-action">DevEx in Action</h2>

<p>Our next article<sup id="fnref:2"><a href="#fn:2" class="footnote" rel="footnote" role="doc-noteref">2</a></sup> is a study of “developer experience and its tangible
impact.” My one critique is that the article doesn’t seem to consider team
turnover and the possible impacts to developer experience there: experience
suffers when picking up a project whose authors are no longer around regardless
of the state of anything else, but certain practices make this easier than
others.</p>

<p>This article uses surveys and statistical techniques to examine a proposed model
of developer experience concerns and relate improvements in developer experience
to tangible individual, team, and organizational outcomes. The statistical
connection provides powerful motivation for business to improve developer
experience:</p>

<blockquote>
  <p>Now that you are sold on improving DevEx, how can you convince your
organization to buy in? First, have them read this article. Then, joke aside,
here are five important steps that can help you advocate for continuous
improvements by keeping your arguments grounded in data.</p>
</blockquote>

<p>The proposed model incorporates flow state, feedback loops, and cognitive load
as the concerns of developer experience. Studied individual factors include
learning, job performance, and creativity. Team factors include code
quality and technical debt. Organizational factors include retention and
profitability. The statistical findings indicate that, for their sample, flow
state and cognitive load positively impacts all outcomes. Feedback loops
influence team outcomes but not individual or organizational outcomes (see the
article for full details).</p>

<p>Here are a few topics I want to highlight.</p>

<h3 id="git">Git</h3>

<p>As many of my <a href="/tags#capital+one" class="tag">Capital One</a> coworkers
know, I have spent a lot of time talking about the many ways in which <a href="/tags#git" class="tag">Git</a> can improve developer experience if only we
spent the time to take advantage of our tools.</p>

<p>Speed and quality of information (“How often it takes &gt;10min to have a question
answered”) is an important aspect of the article’s conception of feedback loops;
this is supported by prior research. I have long argued that Git as a version
control system tracks <em>by default</em> the who, what, when, and where. Arguably the
how can be captured as well when the patches include mechanisms. The only person
who can answer <em>why</em> is the commit author: take the time to write down why the
changes are necessary or important! Then Git becomes the ultimate speedy
answerer: search techniques from code search with <code class="language-plaintext highlighter-rouge">git grep</code> to sophisticated
history searches with <code class="language-plaintext highlighter-rouge">git log</code> and <code class="language-plaintext highlighter-rouge">-G</code>, <code class="language-plaintext highlighter-rouge">-S</code>, or <code class="language-plaintext highlighter-rouge">--grep</code> empower us to find
more information or more threads to tug on from the comfort of our workstation
and development environments. Even <code class="language-plaintext highlighter-rouge">git blame</code> has a role to play in helping us
understand our work. The authors write:</p>

<blockquote>
  <p>Teams that provide fast responses to developers’ questions report 50% less
technical debt than teams whose responses are slow. It pays to document
repeated developer questions and/or put tooling in place so developers can
easily and quickly navigate to the response they need and integrate good
coding practices and solutions as they write their code, which creates less
technical debt.</p>
</blockquote>

<p>Certainly version control is not the only place for such Q&amp;A documentation, but
it should be treated as the wealth of information that it is. This also suggests
that how to find answers to questions is a major (and trainable) skill.</p>

<p>Git shines not only in feedback loops: Git helps offload cognitive burdens, too.
We know that the human brain tends to hold on to incomplete tasks and create
stress while it is able to quickly erase completed tasks and associated stress.
Writing down our thoughts in a commit message is a form of completing the task,
relieving stress. It further enables us to search, not sort, our information:
sorting information is a maintenance intensive burden that doesn’t always lead
to the information being easy to find. Commit messages offload our thoughts into
a kind of searchable exobrain that we share with our teams and our future
colleagues, whether we’re around to work with them or not. Finally, commit
messages assist developers who want to understand code, which is an important
factor in the article’s consideration of cognitive load.</p>

<h3 id="impact">Impact</h3>

<p>I’m not sure much else needs said here:</p>

<blockquote>
  <p>To improve developer outcomes, deep work and engaging work have the biggest
potential impact. To improve organizational outcomes, several items have the
potential for big impact: deep work, engaging work, intuitive processes, and
intuitive developer tools</p>
</blockquote>

<p>By the way, the opposite also holds true:</p>

<blockquote>
  <p>Developers who find their tools and work processes intuitive and easy to use
feel they are 50% more innovative compared with those with opaque or
hard-to-understand processes. Unintuitive tools and processes can be both a
time sink and a source of frustration—in either case, a severe hindrance to
individuals’ and teams’ creativity.</p>
</blockquote>

<p>Since I have otherwise less to say about a third article<sup id="fnref:3"><a href="#fn:3" class="footnote" rel="footnote" role="doc-noteref">3</a></sup>, I’ll quote its
knowledge of automation processes such as CI (see original for citations):</p>

<blockquote>
  <p>However, an immature automation process can result in negative outcomes, such
as cost and schedule overruns, slow feedback loops, and delayed releases.</p>
</blockquote>

<p>“DevEx in Action” presents a framework for making an impact consists of 5 steps,
which I’ll summarize here:</p>

<blockquote>
  <ol>
    <li>Get data on the current developer experience.</li>
    <li>Set goals based on your DevEx data.</li>
    <li>Set your team up for success.</li>
    <li>Share progress and validate investments.</li>
    <li>Repeat the process.</li>
  </ol>
</blockquote>

<p>Coupled with the previous article’s direction on resistance, this provides a
powerful roadmap from which to iterate and improve outcomes.</p>

<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:1">
      <p><a href="https://cacm.acm.org/opinion/resistance-is-your-friend/">Peter Denning and Todd Lyons. 2024. Resistance Is Your Friend. <em>Commun.
ACM 67</em>, 6 (June 2024), 26–29.
https://doi.org/10.1145/3654696</a> <a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:2">
      <p><a href="https://cacm.acm.org/practice/devex-in-action/">Nicole Forsgren, Eirini Kalliamvakou, Abi Noda, Michaela Greiler, Brian
Houck, and Margaret-Anne Storey. 2024. DevEx in Action. <em>Commun. ACM 67</em>, 6
(June 2024), 42–51.
https://doi.org/10.1145/3643140</a> <a href="#fnref:2" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:3">
      <p><a href="https://cacm.acm.org/research/a-roadmap-for-using-continuous-integration-environments/">Liang Yu, Emil Alégroth, Panagiota Chatzipetrou, and Tony Gorschek. 2024.
A Roadmap for Using Continuous Integration Environments. Commun. ACM 67, 6
(June 2024), 82–90.
https://doi.org/10.1145/3631519</a> <a href="#fnref:3" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
  </ol>
</div>]]></content><author><name>D. Ben Knoble</name></author><category term="[&quot;Blog&quot;]" /><category term="developer experience" /><category term="acm" /><summary type="html"><![CDATA[I pull excerpts from recent Communications of the ACM articles relevant to developer experience advocates and add my own commentary.]]></summary></entry></feed>